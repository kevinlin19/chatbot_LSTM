{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/championlin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, RepeatVector\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('conversation.json')\n",
    "data = json.load(file)\n",
    "cor = data['conversations']\n",
    "sentenceList=list(chain(*cor))\n",
    "# sentence = [sentence_to_wordlist(p) for p in  list(chain(*[n for n in cor]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(cor)):\n",
    "    for j in range(len(cor[i])):\n",
    "        if j<len(cor[i])-1:\n",
    "            x.append(cor[i][j])\n",
    "            y.append(cor[i][j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning, how are you?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'morning', ',', 'how', 'are', 'you', '?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(x[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tok=[]\n",
    "y_tok=[]\n",
    "for i in range(len(x)):\n",
    "    x_tok.append(nltk.word_tokenize(x[i].lower()))\n",
    "    y_tok.append(nltk.word_tokenize(y[i].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = x_tok + y_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:39,420 : INFO : collecting all words and their counts\n",
      "2018-03-22 15:20:39,422 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-22 15:20:39,425 : INFO : collected 236 word types from a corpus of 1242 raw words and 172 sentences\n",
      "2018-03-22 15:20:39,427 : INFO : Loading a fresh vocabulary\n",
      "2018-03-22 15:20:39,431 : INFO : min_count=1 retains 236 unique words (100% of original 236, drops 0)\n",
      "2018-03-22 15:20:39,433 : INFO : min_count=1 leaves 1242 word corpus (100% of original 1242, drops 0)\n",
      "2018-03-22 15:20:39,436 : INFO : deleting the raw counts dictionary of 236 items\n",
      "2018-03-22 15:20:39,438 : INFO : sample=0.001 downsamples 79 most-common words\n",
      "2018-03-22 15:20:39,439 : INFO : downsampling leaves estimated 663 word corpus (53.4% of prior 1242)\n",
      "2018-03-22 15:20:39,442 : INFO : estimated required memory for 236 words and 300 dimensions: 684400 bytes\n",
      "2018-03-22 15:20:39,443 : INFO : resetting layer weights\n",
      "2018-03-22 15:20:39,452 : INFO : training model with 1 workers on 236 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-22 15:20:39,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,460 : INFO : EPOCH - 1 : training on 1242 raw words (663 effective words) took 0.0s, 130641 effective words/s\n",
      "2018-03-22 15:20:39,467 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,469 : INFO : EPOCH - 2 : training on 1242 raw words (663 effective words) took 0.0s, 140643 effective words/s\n",
      "2018-03-22 15:20:39,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,476 : INFO : EPOCH - 3 : training on 1242 raw words (648 effective words) took 0.0s, 207161 effective words/s\n",
      "2018-03-22 15:20:39,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,482 : INFO : EPOCH - 4 : training on 1242 raw words (673 effective words) took 0.0s, 193119 effective words/s\n",
      "2018-03-22 15:20:39,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,488 : INFO : EPOCH - 5 : training on 1242 raw words (664 effective words) took 0.0s, 187959 effective words/s\n",
      "2018-03-22 15:20:39,494 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,496 : INFO : EPOCH - 6 : training on 1242 raw words (665 effective words) took 0.0s, 155790 effective words/s\n",
      "2018-03-22 15:20:39,506 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,513 : INFO : EPOCH - 7 : training on 1242 raw words (678 effective words) took 0.0s, 68694 effective words/s\n",
      "2018-03-22 15:20:39,521 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,524 : INFO : EPOCH - 8 : training on 1242 raw words (668 effective words) took 0.0s, 120929 effective words/s\n",
      "2018-03-22 15:20:39,534 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,535 : INFO : EPOCH - 9 : training on 1242 raw words (669 effective words) took 0.0s, 153175 effective words/s\n",
      "2018-03-22 15:20:39,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,548 : INFO : EPOCH - 10 : training on 1242 raw words (657 effective words) took 0.0s, 143933 effective words/s\n",
      "2018-03-22 15:20:39,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,557 : INFO : EPOCH - 11 : training on 1242 raw words (660 effective words) took 0.0s, 158345 effective words/s\n",
      "2018-03-22 15:20:39,565 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,567 : INFO : EPOCH - 12 : training on 1242 raw words (662 effective words) took 0.0s, 137587 effective words/s\n",
      "2018-03-22 15:20:39,574 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,576 : INFO : EPOCH - 13 : training on 1242 raw words (640 effective words) took 0.0s, 133043 effective words/s\n",
      "2018-03-22 15:20:39,583 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,585 : INFO : EPOCH - 14 : training on 1242 raw words (679 effective words) took 0.0s, 279003 effective words/s\n",
      "2018-03-22 15:20:39,590 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,592 : INFO : EPOCH - 15 : training on 1242 raw words (653 effective words) took 0.0s, 177393 effective words/s\n",
      "2018-03-22 15:20:39,597 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,599 : INFO : EPOCH - 16 : training on 1242 raw words (647 effective words) took 0.0s, 231070 effective words/s\n",
      "2018-03-22 15:20:39,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,612 : INFO : EPOCH - 17 : training on 1242 raw words (662 effective words) took 0.0s, 68768 effective words/s\n",
      "2018-03-22 15:20:39,619 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,621 : INFO : EPOCH - 18 : training on 1242 raw words (672 effective words) took 0.0s, 173380 effective words/s\n",
      "2018-03-22 15:20:39,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,633 : INFO : EPOCH - 19 : training on 1242 raw words (657 effective words) took 0.0s, 179382 effective words/s\n",
      "2018-03-22 15:20:39,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,642 : INFO : EPOCH - 20 : training on 1242 raw words (669 effective words) took 0.0s, 124491 effective words/s\n",
      "2018-03-22 15:20:39,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,653 : INFO : EPOCH - 21 : training on 1242 raw words (658 effective words) took 0.0s, 142065 effective words/s\n",
      "2018-03-22 15:20:39,659 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,661 : INFO : EPOCH - 22 : training on 1242 raw words (674 effective words) took 0.0s, 151422 effective words/s\n",
      "2018-03-22 15:20:39,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,672 : INFO : EPOCH - 23 : training on 1242 raw words (680 effective words) took 0.0s, 100935 effective words/s\n",
      "2018-03-22 15:20:39,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,682 : INFO : EPOCH - 24 : training on 1242 raw words (663 effective words) took 0.0s, 148476 effective words/s\n",
      "2018-03-22 15:20:39,691 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,693 : INFO : EPOCH - 25 : training on 1242 raw words (654 effective words) took 0.0s, 134784 effective words/s\n",
      "2018-03-22 15:20:39,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,701 : INFO : EPOCH - 26 : training on 1242 raw words (654 effective words) took 0.0s, 199218 effective words/s\n",
      "2018-03-22 15:20:39,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,707 : INFO : EPOCH - 27 : training on 1242 raw words (659 effective words) took 0.0s, 182245 effective words/s\n",
      "2018-03-22 15:20:39,712 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,714 : INFO : EPOCH - 28 : training on 1242 raw words (662 effective words) took 0.0s, 157956 effective words/s\n",
      "2018-03-22 15:20:39,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,722 : INFO : EPOCH - 29 : training on 1242 raw words (661 effective words) took 0.0s, 143117 effective words/s\n",
      "2018-03-22 15:20:39,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,729 : INFO : EPOCH - 30 : training on 1242 raw words (666 effective words) took 0.0s, 186735 effective words/s\n",
      "2018-03-22 15:20:39,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,741 : INFO : EPOCH - 31 : training on 1242 raw words (689 effective words) took 0.0s, 74699 effective words/s\n",
      "2018-03-22 15:20:39,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,751 : INFO : EPOCH - 32 : training on 1242 raw words (665 effective words) took 0.0s, 161644 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:39,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,762 : INFO : EPOCH - 33 : training on 1242 raw words (661 effective words) took 0.0s, 129061 effective words/s\n",
      "2018-03-22 15:20:39,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,774 : INFO : EPOCH - 34 : training on 1242 raw words (670 effective words) took 0.0s, 83793 effective words/s\n",
      "2018-03-22 15:20:39,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,781 : INFO : EPOCH - 35 : training on 1242 raw words (680 effective words) took 0.0s, 197247 effective words/s\n",
      "2018-03-22 15:20:39,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,788 : INFO : EPOCH - 36 : training on 1242 raw words (648 effective words) took 0.0s, 186846 effective words/s\n",
      "2018-03-22 15:20:39,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,794 : INFO : EPOCH - 37 : training on 1242 raw words (673 effective words) took 0.0s, 193905 effective words/s\n",
      "2018-03-22 15:20:39,799 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,801 : INFO : EPOCH - 38 : training on 1242 raw words (668 effective words) took 0.0s, 200706 effective words/s\n",
      "2018-03-22 15:20:39,806 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,808 : INFO : EPOCH - 39 : training on 1242 raw words (665 effective words) took 0.0s, 199830 effective words/s\n",
      "2018-03-22 15:20:39,812 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,814 : INFO : EPOCH - 40 : training on 1242 raw words (684 effective words) took 0.0s, 214409 effective words/s\n",
      "2018-03-22 15:20:39,819 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,821 : INFO : EPOCH - 41 : training on 1242 raw words (682 effective words) took 0.0s, 167039 effective words/s\n",
      "2018-03-22 15:20:39,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,840 : INFO : EPOCH - 42 : training on 1242 raw words (669 effective words) took 0.0s, 132127 effective words/s\n",
      "2018-03-22 15:20:39,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,851 : INFO : EPOCH - 43 : training on 1242 raw words (681 effective words) took 0.0s, 161470 effective words/s\n",
      "2018-03-22 15:20:39,859 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,862 : INFO : EPOCH - 44 : training on 1242 raw words (668 effective words) took 0.0s, 179887 effective words/s\n",
      "2018-03-22 15:20:39,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,871 : INFO : EPOCH - 45 : training on 1242 raw words (648 effective words) took 0.0s, 179105 effective words/s\n",
      "2018-03-22 15:20:39,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,884 : INFO : EPOCH - 46 : training on 1242 raw words (673 effective words) took 0.0s, 81966 effective words/s\n",
      "2018-03-22 15:20:39,891 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,893 : INFO : EPOCH - 47 : training on 1242 raw words (656 effective words) took 0.0s, 200859 effective words/s\n",
      "2018-03-22 15:20:39,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,900 : INFO : EPOCH - 48 : training on 1242 raw words (679 effective words) took 0.0s, 148232 effective words/s\n",
      "2018-03-22 15:20:39,906 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,909 : INFO : EPOCH - 49 : training on 1242 raw words (669 effective words) took 0.0s, 133059 effective words/s\n",
      "2018-03-22 15:20:39,917 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,919 : INFO : EPOCH - 50 : training on 1242 raw words (667 effective words) took 0.0s, 145466 effective words/s\n",
      "2018-03-22 15:20:39,929 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,931 : INFO : EPOCH - 51 : training on 1242 raw words (664 effective words) took 0.0s, 137987 effective words/s\n",
      "2018-03-22 15:20:39,937 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,939 : INFO : EPOCH - 52 : training on 1242 raw words (659 effective words) took 0.0s, 166148 effective words/s\n",
      "2018-03-22 15:20:39,948 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,950 : INFO : EPOCH - 53 : training on 1242 raw words (658 effective words) took 0.0s, 145161 effective words/s\n",
      "2018-03-22 15:20:39,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,959 : INFO : EPOCH - 54 : training on 1242 raw words (636 effective words) took 0.0s, 257272 effective words/s\n",
      "2018-03-22 15:20:39,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,972 : INFO : EPOCH - 55 : training on 1242 raw words (684 effective words) took 0.0s, 280142 effective words/s\n",
      "2018-03-22 15:20:39,978 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,981 : INFO : EPOCH - 56 : training on 1242 raw words (667 effective words) took 0.0s, 142152 effective words/s\n",
      "2018-03-22 15:20:39,987 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,988 : INFO : EPOCH - 57 : training on 1242 raw words (654 effective words) took 0.0s, 213300 effective words/s\n",
      "2018-03-22 15:20:39,993 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:39,996 : INFO : EPOCH - 58 : training on 1242 raw words (654 effective words) took 0.0s, 114527 effective words/s\n",
      "2018-03-22 15:20:40,007 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,009 : INFO : EPOCH - 59 : training on 1242 raw words (672 effective words) took 0.0s, 133185 effective words/s\n",
      "2018-03-22 15:20:40,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,019 : INFO : EPOCH - 60 : training on 1242 raw words (655 effective words) took 0.0s, 179243 effective words/s\n",
      "2018-03-22 15:20:40,024 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,026 : INFO : EPOCH - 61 : training on 1242 raw words (660 effective words) took 0.0s, 173742 effective words/s\n",
      "2018-03-22 15:20:40,030 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,032 : INFO : EPOCH - 62 : training on 1242 raw words (657 effective words) took 0.0s, 191054 effective words/s\n",
      "2018-03-22 15:20:40,042 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,044 : INFO : EPOCH - 63 : training on 1242 raw words (684 effective words) took 0.0s, 112021 effective words/s\n",
      "2018-03-22 15:20:40,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,050 : INFO : EPOCH - 64 : training on 1242 raw words (644 effective words) took 0.0s, 195901 effective words/s\n",
      "2018-03-22 15:20:40,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,057 : INFO : EPOCH - 65 : training on 1242 raw words (655 effective words) took 0.0s, 181900 effective words/s\n",
      "2018-03-22 15:20:40,064 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,066 : INFO : EPOCH - 66 : training on 1242 raw words (669 effective words) took 0.0s, 151322 effective words/s\n",
      "2018-03-22 15:20:40,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,077 : INFO : EPOCH - 67 : training on 1242 raw words (690 effective words) took 0.0s, 90484 effective words/s\n",
      "2018-03-22 15:20:40,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,086 : INFO : EPOCH - 68 : training on 1242 raw words (654 effective words) took 0.0s, 247192 effective words/s\n",
      "2018-03-22 15:20:40,092 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,097 : INFO : EPOCH - 69 : training on 1242 raw words (682 effective words) took 0.0s, 100981 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:40,102 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,103 : INFO : EPOCH - 70 : training on 1242 raw words (661 effective words) took 0.0s, 184515 effective words/s\n",
      "2018-03-22 15:20:40,109 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,111 : INFO : EPOCH - 71 : training on 1242 raw words (691 effective words) took 0.0s, 147264 effective words/s\n",
      "2018-03-22 15:20:40,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,125 : INFO : EPOCH - 72 : training on 1242 raw words (652 effective words) took 0.0s, 91199 effective words/s\n",
      "2018-03-22 15:20:40,132 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,133 : INFO : EPOCH - 73 : training on 1242 raw words (665 effective words) took 0.0s, 197658 effective words/s\n",
      "2018-03-22 15:20:40,138 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,140 : INFO : EPOCH - 74 : training on 1242 raw words (653 effective words) took 0.0s, 193155 effective words/s\n",
      "2018-03-22 15:20:40,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,150 : INFO : EPOCH - 75 : training on 1242 raw words (657 effective words) took 0.0s, 179753 effective words/s\n",
      "2018-03-22 15:20:40,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,157 : INFO : EPOCH - 76 : training on 1242 raw words (642 effective words) took 0.0s, 173389 effective words/s\n",
      "2018-03-22 15:20:40,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,165 : INFO : EPOCH - 77 : training on 1242 raw words (658 effective words) took 0.0s, 174844 effective words/s\n",
      "2018-03-22 15:20:40,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,173 : INFO : EPOCH - 78 : training on 1242 raw words (668 effective words) took 0.0s, 169422 effective words/s\n",
      "2018-03-22 15:20:40,180 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,182 : INFO : EPOCH - 79 : training on 1242 raw words (663 effective words) took 0.0s, 132301 effective words/s\n",
      "2018-03-22 15:20:40,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,189 : INFO : EPOCH - 80 : training on 1242 raw words (642 effective words) took 0.0s, 273715 effective words/s\n",
      "2018-03-22 15:20:40,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,201 : INFO : EPOCH - 81 : training on 1242 raw words (685 effective words) took 0.0s, 103405 effective words/s\n",
      "2018-03-22 15:20:40,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,210 : INFO : EPOCH - 82 : training on 1242 raw words (645 effective words) took 0.0s, 148602 effective words/s\n",
      "2018-03-22 15:20:40,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,222 : INFO : EPOCH - 83 : training on 1242 raw words (662 effective words) took 0.0s, 96135 effective words/s\n",
      "2018-03-22 15:20:40,228 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,230 : INFO : EPOCH - 84 : training on 1242 raw words (660 effective words) took 0.0s, 203187 effective words/s\n",
      "2018-03-22 15:20:40,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,237 : INFO : EPOCH - 85 : training on 1242 raw words (623 effective words) took 0.0s, 173307 effective words/s\n",
      "2018-03-22 15:20:40,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,248 : INFO : EPOCH - 86 : training on 1242 raw words (660 effective words) took 0.0s, 159377 effective words/s\n",
      "2018-03-22 15:20:40,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,254 : INFO : EPOCH - 87 : training on 1242 raw words (680 effective words) took 0.0s, 189077 effective words/s\n",
      "2018-03-22 15:20:40,259 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,261 : INFO : EPOCH - 88 : training on 1242 raw words (675 effective words) took 0.0s, 175643 effective words/s\n",
      "2018-03-22 15:20:40,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,275 : INFO : EPOCH - 89 : training on 1242 raw words (661 effective words) took 0.0s, 102154 effective words/s\n",
      "2018-03-22 15:20:40,281 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,282 : INFO : EPOCH - 90 : training on 1242 raw words (648 effective words) took 0.0s, 212894 effective words/s\n",
      "2018-03-22 15:20:40,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,290 : INFO : EPOCH - 91 : training on 1242 raw words (657 effective words) took 0.0s, 162468 effective words/s\n",
      "2018-03-22 15:20:40,300 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,302 : INFO : EPOCH - 92 : training on 1242 raw words (666 effective words) took 0.0s, 130632 effective words/s\n",
      "2018-03-22 15:20:40,311 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,313 : INFO : EPOCH - 93 : training on 1242 raw words (664 effective words) took 0.0s, 163618 effective words/s\n",
      "2018-03-22 15:20:40,318 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,320 : INFO : EPOCH - 94 : training on 1242 raw words (659 effective words) took 0.0s, 163368 effective words/s\n",
      "2018-03-22 15:20:40,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,329 : INFO : EPOCH - 95 : training on 1242 raw words (687 effective words) took 0.0s, 100582 effective words/s\n",
      "2018-03-22 15:20:40,336 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,339 : INFO : EPOCH - 96 : training on 1242 raw words (661 effective words) took 0.0s, 114047 effective words/s\n",
      "2018-03-22 15:20:40,347 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,349 : INFO : EPOCH - 97 : training on 1242 raw words (662 effective words) took 0.0s, 210011 effective words/s\n",
      "2018-03-22 15:20:40,354 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,355 : INFO : EPOCH - 98 : training on 1242 raw words (663 effective words) took 0.0s, 183171 effective words/s\n",
      "2018-03-22 15:20:40,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,367 : INFO : EPOCH - 99 : training on 1242 raw words (651 effective words) took 0.0s, 99380 effective words/s\n",
      "2018-03-22 15:20:40,377 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,379 : INFO : EPOCH - 100 : training on 1242 raw words (663 effective words) took 0.0s, 129073 effective words/s\n",
      "2018-03-22 15:20:40,383 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,385 : INFO : EPOCH - 101 : training on 1242 raw words (673 effective words) took 0.0s, 242863 effective words/s\n",
      "2018-03-22 15:20:40,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,393 : INFO : EPOCH - 102 : training on 1242 raw words (648 effective words) took 0.0s, 136759 effective words/s\n",
      "2018-03-22 15:20:40,401 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,402 : INFO : EPOCH - 103 : training on 1242 raw words (642 effective words) took 0.0s, 170506 effective words/s\n",
      "2018-03-22 15:20:40,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,413 : INFO : EPOCH - 104 : training on 1242 raw words (658 effective words) took 0.0s, 107743 effective words/s\n",
      "2018-03-22 15:20:40,417 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,419 : INFO : EPOCH - 105 : training on 1242 raw words (680 effective words) took 0.0s, 230901 effective words/s\n",
      "2018-03-22 15:20:40,425 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:40,428 : INFO : EPOCH - 106 : training on 1242 raw words (686 effective words) took 0.0s, 134094 effective words/s\n",
      "2018-03-22 15:20:40,435 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,438 : INFO : EPOCH - 107 : training on 1242 raw words (653 effective words) took 0.0s, 135772 effective words/s\n",
      "2018-03-22 15:20:40,444 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,447 : INFO : EPOCH - 108 : training on 1242 raw words (673 effective words) took 0.0s, 168118 effective words/s\n",
      "2018-03-22 15:20:40,453 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,455 : INFO : EPOCH - 109 : training on 1242 raw words (655 effective words) took 0.0s, 215502 effective words/s\n",
      "2018-03-22 15:20:40,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,466 : INFO : EPOCH - 110 : training on 1242 raw words (649 effective words) took 0.0s, 114279 effective words/s\n",
      "2018-03-22 15:20:40,476 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,478 : INFO : EPOCH - 111 : training on 1242 raw words (680 effective words) took 0.0s, 172712 effective words/s\n",
      "2018-03-22 15:20:40,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,485 : INFO : EPOCH - 112 : training on 1242 raw words (683 effective words) took 0.0s, 185089 effective words/s\n",
      "2018-03-22 15:20:40,489 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,492 : INFO : EPOCH - 113 : training on 1242 raw words (647 effective words) took 0.0s, 143315 effective words/s\n",
      "2018-03-22 15:20:40,498 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,500 : INFO : EPOCH - 114 : training on 1242 raw words (652 effective words) took 0.0s, 155402 effective words/s\n",
      "2018-03-22 15:20:40,506 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,508 : INFO : EPOCH - 115 : training on 1242 raw words (663 effective words) took 0.0s, 153077 effective words/s\n",
      "2018-03-22 15:20:40,515 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,517 : INFO : EPOCH - 116 : training on 1242 raw words (661 effective words) took 0.0s, 130592 effective words/s\n",
      "2018-03-22 15:20:40,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,529 : INFO : EPOCH - 117 : training on 1242 raw words (671 effective words) took 0.0s, 122416 effective words/s\n",
      "2018-03-22 15:20:40,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,540 : INFO : EPOCH - 118 : training on 1242 raw words (641 effective words) took 0.0s, 159600 effective words/s\n",
      "2018-03-22 15:20:40,547 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,548 : INFO : EPOCH - 119 : training on 1242 raw words (657 effective words) took 0.0s, 149985 effective words/s\n",
      "2018-03-22 15:20:40,557 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,560 : INFO : EPOCH - 120 : training on 1242 raw words (680 effective words) took 0.0s, 119597 effective words/s\n",
      "2018-03-22 15:20:40,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,573 : INFO : EPOCH - 121 : training on 1242 raw words (651 effective words) took 0.0s, 160578 effective words/s\n",
      "2018-03-22 15:20:40,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,584 : INFO : EPOCH - 122 : training on 1242 raw words (654 effective words) took 0.0s, 127381 effective words/s\n",
      "2018-03-22 15:20:40,590 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,592 : INFO : EPOCH - 123 : training on 1242 raw words (672 effective words) took 0.0s, 147231 effective words/s\n",
      "2018-03-22 15:20:40,597 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,599 : INFO : EPOCH - 124 : training on 1242 raw words (641 effective words) took 0.0s, 207588 effective words/s\n",
      "2018-03-22 15:20:40,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,612 : INFO : EPOCH - 125 : training on 1242 raw words (689 effective words) took 0.0s, 152105 effective words/s\n",
      "2018-03-22 15:20:40,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,621 : INFO : EPOCH - 126 : training on 1242 raw words (677 effective words) took 0.0s, 153819 effective words/s\n",
      "2018-03-22 15:20:40,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,629 : INFO : EPOCH - 127 : training on 1242 raw words (644 effective words) took 0.0s, 166329 effective words/s\n",
      "2018-03-22 15:20:40,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,639 : INFO : EPOCH - 128 : training on 1242 raw words (669 effective words) took 0.0s, 114352 effective words/s\n",
      "2018-03-22 15:20:40,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,648 : INFO : EPOCH - 129 : training on 1242 raw words (666 effective words) took 0.0s, 150124 effective words/s\n",
      "2018-03-22 15:20:40,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,655 : INFO : EPOCH - 130 : training on 1242 raw words (667 effective words) took 0.0s, 168758 effective words/s\n",
      "2018-03-22 15:20:40,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,666 : INFO : EPOCH - 131 : training on 1242 raw words (672 effective words) took 0.0s, 111359 effective words/s\n",
      "2018-03-22 15:20:40,672 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,675 : INFO : EPOCH - 132 : training on 1242 raw words (672 effective words) took 0.0s, 157103 effective words/s\n",
      "2018-03-22 15:20:40,683 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,685 : INFO : EPOCH - 133 : training on 1242 raw words (644 effective words) took 0.0s, 165138 effective words/s\n",
      "2018-03-22 15:20:40,691 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,694 : INFO : EPOCH - 134 : training on 1242 raw words (654 effective words) took 0.0s, 132797 effective words/s\n",
      "2018-03-22 15:20:40,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,703 : INFO : EPOCH - 135 : training on 1242 raw words (661 effective words) took 0.0s, 173688 effective words/s\n",
      "2018-03-22 15:20:40,709 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,712 : INFO : EPOCH - 136 : training on 1242 raw words (677 effective words) took 0.0s, 150176 effective words/s\n",
      "2018-03-22 15:20:40,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,722 : INFO : EPOCH - 137 : training on 1242 raw words (669 effective words) took 0.0s, 163127 effective words/s\n",
      "2018-03-22 15:20:40,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,733 : INFO : EPOCH - 138 : training on 1242 raw words (675 effective words) took 0.0s, 120113 effective words/s\n",
      "2018-03-22 15:20:40,739 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,741 : INFO : EPOCH - 139 : training on 1242 raw words (665 effective words) took 0.0s, 169452 effective words/s\n",
      "2018-03-22 15:20:40,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,748 : INFO : EPOCH - 140 : training on 1242 raw words (666 effective words) took 0.0s, 179029 effective words/s\n",
      "2018-03-22 15:20:40,754 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,755 : INFO : EPOCH - 141 : training on 1242 raw words (675 effective words) took 0.0s, 217333 effective words/s\n",
      "2018-03-22 15:20:40,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,764 : INFO : EPOCH - 142 : training on 1242 raw words (676 effective words) took 0.0s, 145912 effective words/s\n",
      "2018-03-22 15:20:40,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:40,776 : INFO : EPOCH - 143 : training on 1242 raw words (634 effective words) took 0.0s, 190636 effective words/s\n",
      "2018-03-22 15:20:40,784 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,785 : INFO : EPOCH - 144 : training on 1242 raw words (662 effective words) took 0.0s, 194750 effective words/s\n",
      "2018-03-22 15:20:40,791 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,793 : INFO : EPOCH - 145 : training on 1242 raw words (678 effective words) took 0.0s, 165761 effective words/s\n",
      "2018-03-22 15:20:40,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,800 : INFO : EPOCH - 146 : training on 1242 raw words (677 effective words) took 0.0s, 197030 effective words/s\n",
      "2018-03-22 15:20:40,806 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,811 : INFO : EPOCH - 147 : training on 1242 raw words (664 effective words) took 0.0s, 107764 effective words/s\n",
      "2018-03-22 15:20:40,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,818 : INFO : EPOCH - 148 : training on 1242 raw words (647 effective words) took 0.0s, 172575 effective words/s\n",
      "2018-03-22 15:20:40,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,826 : INFO : EPOCH - 149 : training on 1242 raw words (667 effective words) took 0.0s, 151703 effective words/s\n",
      "2018-03-22 15:20:40,833 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,835 : INFO : EPOCH - 150 : training on 1242 raw words (669 effective words) took 0.0s, 210980 effective words/s\n",
      "2018-03-22 15:20:40,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,843 : INFO : EPOCH - 151 : training on 1242 raw words (685 effective words) took 0.0s, 171403 effective words/s\n",
      "2018-03-22 15:20:40,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,851 : INFO : EPOCH - 152 : training on 1242 raw words (659 effective words) took 0.0s, 121191 effective words/s\n",
      "2018-03-22 15:20:40,857 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,859 : INFO : EPOCH - 153 : training on 1242 raw words (661 effective words) took 0.0s, 152798 effective words/s\n",
      "2018-03-22 15:20:40,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,869 : INFO : EPOCH - 154 : training on 1242 raw words (676 effective words) took 0.0s, 178666 effective words/s\n",
      "2018-03-22 15:20:40,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,877 : INFO : EPOCH - 155 : training on 1242 raw words (623 effective words) took 0.0s, 130283 effective words/s\n",
      "2018-03-22 15:20:40,885 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,887 : INFO : EPOCH - 156 : training on 1242 raw words (662 effective words) took 0.0s, 97571 effective words/s\n",
      "2018-03-22 15:20:40,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,895 : INFO : EPOCH - 157 : training on 1242 raw words (667 effective words) took 0.0s, 154063 effective words/s\n",
      "2018-03-22 15:20:40,904 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,905 : INFO : EPOCH - 158 : training on 1242 raw words (660 effective words) took 0.0s, 185839 effective words/s\n",
      "2018-03-22 15:20:40,911 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,914 : INFO : EPOCH - 159 : training on 1242 raw words (680 effective words) took 0.0s, 137763 effective words/s\n",
      "2018-03-22 15:20:40,920 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,925 : INFO : EPOCH - 160 : training on 1242 raw words (662 effective words) took 0.0s, 92444 effective words/s\n",
      "2018-03-22 15:20:40,930 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,932 : INFO : EPOCH - 161 : training on 1242 raw words (658 effective words) took 0.0s, 147124 effective words/s\n",
      "2018-03-22 15:20:40,937 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,939 : INFO : EPOCH - 162 : training on 1242 raw words (661 effective words) took 0.0s, 210723 effective words/s\n",
      "2018-03-22 15:20:40,948 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,951 : INFO : EPOCH - 163 : training on 1242 raw words (671 effective words) took 0.0s, 117344 effective words/s\n",
      "2018-03-22 15:20:40,956 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,959 : INFO : EPOCH - 164 : training on 1242 raw words (645 effective words) took 0.0s, 131356 effective words/s\n",
      "2018-03-22 15:20:40,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,972 : INFO : EPOCH - 165 : training on 1242 raw words (670 effective words) took 0.0s, 157592 effective words/s\n",
      "2018-03-22 15:20:40,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,982 : INFO : EPOCH - 166 : training on 1242 raw words (641 effective words) took 0.0s, 116534 effective words/s\n",
      "2018-03-22 15:20:40,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,989 : INFO : EPOCH - 167 : training on 1242 raw words (653 effective words) took 0.0s, 215180 effective words/s\n",
      "2018-03-22 15:20:40,995 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:40,997 : INFO : EPOCH - 168 : training on 1242 raw words (663 effective words) took 0.0s, 173578 effective words/s\n",
      "2018-03-22 15:20:41,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,006 : INFO : EPOCH - 169 : training on 1242 raw words (644 effective words) took 0.0s, 136103 effective words/s\n",
      "2018-03-22 15:20:41,014 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,016 : INFO : EPOCH - 170 : training on 1242 raw words (634 effective words) took 0.0s, 161763 effective words/s\n",
      "2018-03-22 15:20:41,020 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,022 : INFO : EPOCH - 171 : training on 1242 raw words (668 effective words) took 0.0s, 191807 effective words/s\n",
      "2018-03-22 15:20:41,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,029 : INFO : EPOCH - 172 : training on 1242 raw words (631 effective words) took 0.0s, 147685 effective words/s\n",
      "2018-03-22 15:20:41,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,039 : INFO : EPOCH - 173 : training on 1242 raw words (672 effective words) took 0.0s, 144406 effective words/s\n",
      "2018-03-22 15:20:41,046 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,047 : INFO : EPOCH - 174 : training on 1242 raw words (658 effective words) took 0.0s, 176969 effective words/s\n",
      "2018-03-22 15:20:41,056 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,058 : INFO : EPOCH - 175 : training on 1242 raw words (649 effective words) took 0.0s, 181261 effective words/s\n",
      "2018-03-22 15:20:41,066 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,068 : INFO : EPOCH - 176 : training on 1242 raw words (668 effective words) took 0.0s, 115307 effective words/s\n",
      "2018-03-22 15:20:41,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,075 : INFO : EPOCH - 177 : training on 1242 raw words (663 effective words) took 0.0s, 193460 effective words/s\n",
      "2018-03-22 15:20:41,081 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,082 : INFO : EPOCH - 178 : training on 1242 raw words (657 effective words) took 0.0s, 198946 effective words/s\n",
      "2018-03-22 15:20:41,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,094 : INFO : EPOCH - 179 : training on 1242 raw words (670 effective words) took 0.0s, 87106 effective words/s\n",
      "2018-03-22 15:20:41,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:41,102 : INFO : EPOCH - 180 : training on 1242 raw words (647 effective words) took 0.0s, 155599 effective words/s\n",
      "2018-03-22 15:20:41,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,108 : INFO : EPOCH - 181 : training on 1242 raw words (649 effective words) took 0.0s, 193888 effective words/s\n",
      "2018-03-22 15:20:41,117 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,118 : INFO : EPOCH - 182 : training on 1242 raw words (675 effective words) took 0.0s, 115192 effective words/s\n",
      "2018-03-22 15:20:41,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,125 : INFO : EPOCH - 183 : training on 1242 raw words (665 effective words) took 0.0s, 179559 effective words/s\n",
      "2018-03-22 15:20:41,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,137 : INFO : EPOCH - 184 : training on 1242 raw words (651 effective words) took 0.0s, 78242 effective words/s\n",
      "2018-03-22 15:20:41,143 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,144 : INFO : EPOCH - 185 : training on 1242 raw words (652 effective words) took 0.0s, 155923 effective words/s\n",
      "2018-03-22 15:20:41,152 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,154 : INFO : EPOCH - 186 : training on 1242 raw words (678 effective words) took 0.0s, 204553 effective words/s\n",
      "2018-03-22 15:20:41,159 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,161 : INFO : EPOCH - 187 : training on 1242 raw words (660 effective words) took 0.0s, 151831 effective words/s\n",
      "2018-03-22 15:20:41,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,168 : INFO : EPOCH - 188 : training on 1242 raw words (675 effective words) took 0.0s, 162926 effective words/s\n",
      "2018-03-22 15:20:41,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,175 : INFO : EPOCH - 189 : training on 1242 raw words (677 effective words) took 0.0s, 163996 effective words/s\n",
      "2018-03-22 15:20:41,180 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,182 : INFO : EPOCH - 190 : training on 1242 raw words (660 effective words) took 0.0s, 191832 effective words/s\n",
      "2018-03-22 15:20:41,190 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,192 : INFO : EPOCH - 191 : training on 1242 raw words (655 effective words) took 0.0s, 130883 effective words/s\n",
      "2018-03-22 15:20:41,199 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,202 : INFO : EPOCH - 192 : training on 1242 raw words (639 effective words) took 0.0s, 126913 effective words/s\n",
      "2018-03-22 15:20:41,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,210 : INFO : EPOCH - 193 : training on 1242 raw words (631 effective words) took 0.0s, 139148 effective words/s\n",
      "2018-03-22 15:20:41,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,221 : INFO : EPOCH - 194 : training on 1242 raw words (659 effective words) took 0.0s, 136409 effective words/s\n",
      "2018-03-22 15:20:41,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,230 : INFO : EPOCH - 195 : training on 1242 raw words (682 effective words) took 0.0s, 148660 effective words/s\n",
      "2018-03-22 15:20:41,237 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,239 : INFO : EPOCH - 196 : training on 1242 raw words (706 effective words) took 0.0s, 201834 effective words/s\n",
      "2018-03-22 15:20:41,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,247 : INFO : EPOCH - 197 : training on 1242 raw words (658 effective words) took 0.0s, 201235 effective words/s\n",
      "2018-03-22 15:20:41,251 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,254 : INFO : EPOCH - 198 : training on 1242 raw words (646 effective words) took 0.0s, 161091 effective words/s\n",
      "2018-03-22 15:20:41,260 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,262 : INFO : EPOCH - 199 : training on 1242 raw words (678 effective words) took 0.0s, 165000 effective words/s\n",
      "2018-03-22 15:20:41,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,271 : INFO : EPOCH - 200 : training on 1242 raw words (681 effective words) took 0.0s, 170646 effective words/s\n",
      "2018-03-22 15:20:41,277 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,279 : INFO : EPOCH - 201 : training on 1242 raw words (649 effective words) took 0.0s, 164343 effective words/s\n",
      "2018-03-22 15:20:41,285 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,287 : INFO : EPOCH - 202 : training on 1242 raw words (666 effective words) took 0.0s, 198566 effective words/s\n",
      "2018-03-22 15:20:41,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,294 : INFO : EPOCH - 203 : training on 1242 raw words (651 effective words) took 0.0s, 179425 effective words/s\n",
      "2018-03-22 15:20:41,302 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,306 : INFO : EPOCH - 204 : training on 1242 raw words (675 effective words) took 0.0s, 113459 effective words/s\n",
      "2018-03-22 15:20:41,311 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,312 : INFO : EPOCH - 205 : training on 1242 raw words (651 effective words) took 0.0s, 209232 effective words/s\n",
      "2018-03-22 15:20:41,318 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,320 : INFO : EPOCH - 206 : training on 1242 raw words (657 effective words) took 0.0s, 167346 effective words/s\n",
      "2018-03-22 15:20:41,326 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,330 : INFO : EPOCH - 207 : training on 1242 raw words (654 effective words) took 0.0s, 104933 effective words/s\n",
      "2018-03-22 15:20:41,340 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,342 : INFO : EPOCH - 208 : training on 1242 raw words (670 effective words) took 0.0s, 166377 effective words/s\n",
      "2018-03-22 15:20:41,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,353 : INFO : EPOCH - 209 : training on 1242 raw words (646 effective words) took 0.0s, 160102 effective words/s\n",
      "2018-03-22 15:20:41,359 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,363 : INFO : EPOCH - 210 : training on 1242 raw words (670 effective words) took 0.0s, 109462 effective words/s\n",
      "2018-03-22 15:20:41,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,373 : INFO : EPOCH - 211 : training on 1242 raw words (651 effective words) took 0.0s, 102378 effective words/s\n",
      "2018-03-22 15:20:41,383 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,385 : INFO : EPOCH - 212 : training on 1242 raw words (663 effective words) took 0.0s, 180939 effective words/s\n",
      "2018-03-22 15:20:41,390 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,393 : INFO : EPOCH - 213 : training on 1242 raw words (656 effective words) took 0.0s, 133504 effective words/s\n",
      "2018-03-22 15:20:41,399 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,401 : INFO : EPOCH - 214 : training on 1242 raw words (648 effective words) took 0.0s, 153338 effective words/s\n",
      "2018-03-22 15:20:41,406 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,410 : INFO : EPOCH - 215 : training on 1242 raw words (656 effective words) took 0.0s, 131429 effective words/s\n",
      "2018-03-22 15:20:41,420 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,422 : INFO : EPOCH - 216 : training on 1242 raw words (674 effective words) took 0.0s, 160248 effective words/s\n",
      "2018-03-22 15:20:41,428 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:41,430 : INFO : EPOCH - 217 : training on 1242 raw words (623 effective words) took 0.0s, 139035 effective words/s\n",
      "2018-03-22 15:20:41,438 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,440 : INFO : EPOCH - 218 : training on 1242 raw words (660 effective words) took 0.0s, 127863 effective words/s\n",
      "2018-03-22 15:20:41,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,448 : INFO : EPOCH - 219 : training on 1242 raw words (670 effective words) took 0.0s, 135599 effective words/s\n",
      "2018-03-22 15:20:41,454 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,456 : INFO : EPOCH - 220 : training on 1242 raw words (665 effective words) took 0.0s, 131416 effective words/s\n",
      "2018-03-22 15:20:41,465 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,467 : INFO : EPOCH - 221 : training on 1242 raw words (655 effective words) took 0.0s, 236795 effective words/s\n",
      "2018-03-22 15:20:41,475 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,477 : INFO : EPOCH - 222 : training on 1242 raw words (663 effective words) took 0.0s, 126995 effective words/s\n",
      "2018-03-22 15:20:41,485 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,487 : INFO : EPOCH - 223 : training on 1242 raw words (640 effective words) took 0.0s, 223901 effective words/s\n",
      "2018-03-22 15:20:41,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,495 : INFO : EPOCH - 224 : training on 1242 raw words (677 effective words) took 0.0s, 150095 effective words/s\n",
      "2018-03-22 15:20:41,500 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,502 : INFO : EPOCH - 225 : training on 1242 raw words (656 effective words) took 0.0s, 161098 effective words/s\n",
      "2018-03-22 15:20:41,508 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,510 : INFO : EPOCH - 226 : training on 1242 raw words (634 effective words) took 0.0s, 139602 effective words/s\n",
      "2018-03-22 15:20:41,516 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,519 : INFO : EPOCH - 227 : training on 1242 raw words (659 effective words) took 0.0s, 123351 effective words/s\n",
      "2018-03-22 15:20:41,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,528 : INFO : EPOCH - 228 : training on 1242 raw words (644 effective words) took 0.0s, 143646 effective words/s\n",
      "2018-03-22 15:20:41,539 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,540 : INFO : EPOCH - 229 : training on 1242 raw words (671 effective words) took 0.0s, 117937 effective words/s\n",
      "2018-03-22 15:20:41,548 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,549 : INFO : EPOCH - 230 : training on 1242 raw words (684 effective words) took 0.0s, 204082 effective words/s\n",
      "2018-03-22 15:20:41,557 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,559 : INFO : EPOCH - 231 : training on 1242 raw words (674 effective words) took 0.0s, 143985 effective words/s\n",
      "2018-03-22 15:20:41,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,574 : INFO : EPOCH - 232 : training on 1242 raw words (653 effective words) took 0.0s, 77628 effective words/s\n",
      "2018-03-22 15:20:41,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,585 : INFO : EPOCH - 233 : training on 1242 raw words (657 effective words) took 0.0s, 101723 effective words/s\n",
      "2018-03-22 15:20:41,592 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,597 : INFO : EPOCH - 234 : training on 1242 raw words (643 effective words) took 0.0s, 100556 effective words/s\n",
      "2018-03-22 15:20:41,606 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,608 : INFO : EPOCH - 235 : training on 1242 raw words (684 effective words) took 0.0s, 124992 effective words/s\n",
      "2018-03-22 15:20:41,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,624 : INFO : EPOCH - 236 : training on 1242 raw words (676 effective words) took 0.0s, 90948 effective words/s\n",
      "2018-03-22 15:20:41,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,643 : INFO : EPOCH - 237 : training on 1242 raw words (693 effective words) took 0.0s, 127304 effective words/s\n",
      "2018-03-22 15:20:41,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,653 : INFO : EPOCH - 238 : training on 1242 raw words (663 effective words) took 0.0s, 145892 effective words/s\n",
      "2018-03-22 15:20:41,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,665 : INFO : EPOCH - 239 : training on 1242 raw words (670 effective words) took 0.0s, 110115 effective words/s\n",
      "2018-03-22 15:20:41,685 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,692 : INFO : EPOCH - 240 : training on 1242 raw words (659 effective words) took 0.0s, 62267 effective words/s\n",
      "2018-03-22 15:20:41,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,702 : INFO : EPOCH - 241 : training on 1242 raw words (657 effective words) took 0.0s, 123178 effective words/s\n",
      "2018-03-22 15:20:41,709 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,715 : INFO : EPOCH - 242 : training on 1242 raw words (680 effective words) took 0.0s, 77105 effective words/s\n",
      "2018-03-22 15:20:41,739 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,744 : INFO : EPOCH - 243 : training on 1242 raw words (676 effective words) took 0.0s, 69295 effective words/s\n",
      "2018-03-22 15:20:41,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,765 : INFO : EPOCH - 244 : training on 1242 raw words (684 effective words) took 0.0s, 85401 effective words/s\n",
      "2018-03-22 15:20:41,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,774 : INFO : EPOCH - 245 : training on 1242 raw words (682 effective words) took 0.0s, 143051 effective words/s\n",
      "2018-03-22 15:20:41,783 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,786 : INFO : EPOCH - 246 : training on 1242 raw words (651 effective words) took 0.0s, 100659 effective words/s\n",
      "2018-03-22 15:20:41,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,798 : INFO : EPOCH - 247 : training on 1242 raw words (652 effective words) took 0.0s, 128093 effective words/s\n",
      "2018-03-22 15:20:41,804 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,806 : INFO : EPOCH - 248 : training on 1242 raw words (654 effective words) took 0.0s, 205033 effective words/s\n",
      "2018-03-22 15:20:41,821 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,823 : INFO : EPOCH - 249 : training on 1242 raw words (650 effective words) took 0.0s, 83311 effective words/s\n",
      "2018-03-22 15:20:41,839 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,840 : INFO : EPOCH - 250 : training on 1242 raw words (648 effective words) took 0.0s, 124649 effective words/s\n",
      "2018-03-22 15:20:41,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,856 : INFO : EPOCH - 251 : training on 1242 raw words (665 effective words) took 0.0s, 137454 effective words/s\n",
      "2018-03-22 15:20:41,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,870 : INFO : EPOCH - 252 : training on 1242 raw words (654 effective words) took 0.0s, 73155 effective words/s\n",
      "2018-03-22 15:20:41,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,881 : INFO : EPOCH - 253 : training on 1242 raw words (668 effective words) took 0.0s, 101382 effective words/s\n",
      "2018-03-22 15:20:41,891 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:41,895 : INFO : EPOCH - 254 : training on 1242 raw words (693 effective words) took 0.0s, 129906 effective words/s\n",
      "2018-03-22 15:20:41,908 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,910 : INFO : EPOCH - 255 : training on 1242 raw words (675 effective words) took 0.0s, 153391 effective words/s\n",
      "2018-03-22 15:20:41,921 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,923 : INFO : EPOCH - 256 : training on 1242 raw words (679 effective words) took 0.0s, 109931 effective words/s\n",
      "2018-03-22 15:20:41,935 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,938 : INFO : EPOCH - 257 : training on 1242 raw words (677 effective words) took 0.0s, 96106 effective words/s\n",
      "2018-03-22 15:20:41,942 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,947 : INFO : EPOCH - 258 : training on 1242 raw words (656 effective words) took 0.0s, 94627 effective words/s\n",
      "2018-03-22 15:20:41,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,959 : INFO : EPOCH - 259 : training on 1242 raw words (693 effective words) took 0.0s, 169013 effective words/s\n",
      "2018-03-22 15:20:41,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,972 : INFO : EPOCH - 260 : training on 1242 raw words (653 effective words) took 0.0s, 162776 effective words/s\n",
      "2018-03-22 15:20:41,983 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:41,988 : INFO : EPOCH - 261 : training on 1242 raw words (674 effective words) took 0.0s, 118448 effective words/s\n",
      "2018-03-22 15:20:41,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,000 : INFO : EPOCH - 262 : training on 1242 raw words (653 effective words) took 0.0s, 107115 effective words/s\n",
      "2018-03-22 15:20:42,008 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,010 : INFO : EPOCH - 263 : training on 1242 raw words (635 effective words) took 0.0s, 178045 effective words/s\n",
      "2018-03-22 15:20:42,020 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,023 : INFO : EPOCH - 264 : training on 1242 raw words (665 effective words) took 0.0s, 171165 effective words/s\n",
      "2018-03-22 15:20:42,031 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,034 : INFO : EPOCH - 265 : training on 1242 raw words (661 effective words) took 0.0s, 136983 effective words/s\n",
      "2018-03-22 15:20:42,041 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,043 : INFO : EPOCH - 266 : training on 1242 raw words (658 effective words) took 0.0s, 131805 effective words/s\n",
      "2018-03-22 15:20:42,053 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,055 : INFO : EPOCH - 267 : training on 1242 raw words (688 effective words) took 0.0s, 162927 effective words/s\n",
      "2018-03-22 15:20:42,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,073 : INFO : EPOCH - 268 : training on 1242 raw words (653 effective words) took 0.0s, 116627 effective words/s\n",
      "2018-03-22 15:20:42,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,088 : INFO : EPOCH - 269 : training on 1242 raw words (686 effective words) took 0.0s, 162771 effective words/s\n",
      "2018-03-22 15:20:42,093 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,098 : INFO : EPOCH - 270 : training on 1242 raw words (660 effective words) took 0.0s, 86969 effective words/s\n",
      "2018-03-22 15:20:42,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,109 : INFO : EPOCH - 271 : training on 1242 raw words (648 effective words) took 0.0s, 165465 effective words/s\n",
      "2018-03-22 15:20:42,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,124 : INFO : EPOCH - 272 : training on 1242 raw words (663 effective words) took 0.0s, 264069 effective words/s\n",
      "2018-03-22 15:20:42,132 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,137 : INFO : EPOCH - 273 : training on 1242 raw words (639 effective words) took 0.0s, 103249 effective words/s\n",
      "2018-03-22 15:20:42,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,150 : INFO : EPOCH - 274 : training on 1242 raw words (650 effective words) took 0.0s, 122302 effective words/s\n",
      "2018-03-22 15:20:42,156 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,160 : INFO : EPOCH - 275 : training on 1242 raw words (655 effective words) took 0.0s, 182425 effective words/s\n",
      "2018-03-22 15:20:42,165 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,167 : INFO : EPOCH - 276 : training on 1242 raw words (645 effective words) took 0.0s, 140815 effective words/s\n",
      "2018-03-22 15:20:42,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,175 : INFO : EPOCH - 277 : training on 1242 raw words (673 effective words) took 0.0s, 177758 effective words/s\n",
      "2018-03-22 15:20:42,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,184 : INFO : EPOCH - 278 : training on 1242 raw words (670 effective words) took 0.0s, 154573 effective words/s\n",
      "2018-03-22 15:20:42,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,193 : INFO : EPOCH - 279 : training on 1242 raw words (653 effective words) took 0.0s, 191004 effective words/s\n",
      "2018-03-22 15:20:42,199 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,200 : INFO : EPOCH - 280 : training on 1242 raw words (661 effective words) took 0.0s, 162730 effective words/s\n",
      "2018-03-22 15:20:42,205 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,206 : INFO : EPOCH - 281 : training on 1242 raw words (685 effective words) took 0.0s, 218090 effective words/s\n",
      "2018-03-22 15:20:42,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,217 : INFO : EPOCH - 282 : training on 1242 raw words (664 effective words) took 0.0s, 146397 effective words/s\n",
      "2018-03-22 15:20:42,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,227 : INFO : EPOCH - 283 : training on 1242 raw words (649 effective words) took 0.0s, 113056 effective words/s\n",
      "2018-03-22 15:20:42,233 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,235 : INFO : EPOCH - 284 : training on 1242 raw words (658 effective words) took 0.0s, 153851 effective words/s\n",
      "2018-03-22 15:20:42,241 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,243 : INFO : EPOCH - 285 : training on 1242 raw words (662 effective words) took 0.0s, 136861 effective words/s\n",
      "2018-03-22 15:20:42,250 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,252 : INFO : EPOCH - 286 : training on 1242 raw words (657 effective words) took 0.0s, 189159 effective words/s\n",
      "2018-03-22 15:20:42,259 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,261 : INFO : EPOCH - 287 : training on 1242 raw words (676 effective words) took 0.0s, 153350 effective words/s\n",
      "2018-03-22 15:20:42,268 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,270 : INFO : EPOCH - 288 : training on 1242 raw words (686 effective words) took 0.0s, 148691 effective words/s\n",
      "2018-03-22 15:20:42,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,281 : INFO : EPOCH - 289 : training on 1242 raw words (655 effective words) took 0.0s, 134969 effective words/s\n",
      "2018-03-22 15:20:42,286 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,288 : INFO : EPOCH - 290 : training on 1242 raw words (639 effective words) took 0.0s, 174636 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 15:20:42,294 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,299 : INFO : EPOCH - 291 : training on 1242 raw words (682 effective words) took 0.0s, 111637 effective words/s\n",
      "2018-03-22 15:20:42,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,313 : INFO : EPOCH - 292 : training on 1242 raw words (659 effective words) took 0.0s, 94214 effective words/s\n",
      "2018-03-22 15:20:42,318 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,319 : INFO : EPOCH - 293 : training on 1242 raw words (660 effective words) took 0.0s, 288704 effective words/s\n",
      "2018-03-22 15:20:42,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,327 : INFO : EPOCH - 294 : training on 1242 raw words (658 effective words) took 0.0s, 173914 effective words/s\n",
      "2018-03-22 15:20:42,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,337 : INFO : EPOCH - 295 : training on 1242 raw words (656 effective words) took 0.0s, 176480 effective words/s\n",
      "2018-03-22 15:20:42,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,345 : INFO : EPOCH - 296 : training on 1242 raw words (662 effective words) took 0.0s, 170076 effective words/s\n",
      "2018-03-22 15:20:42,350 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,351 : INFO : EPOCH - 297 : training on 1242 raw words (656 effective words) took 0.0s, 219466 effective words/s\n",
      "2018-03-22 15:20:42,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,360 : INFO : EPOCH - 298 : training on 1242 raw words (660 effective words) took 0.0s, 136083 effective words/s\n",
      "2018-03-22 15:20:42,366 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,369 : INFO : EPOCH - 299 : training on 1242 raw words (655 effective words) took 0.0s, 138066 effective words/s\n",
      "2018-03-22 15:20:42,375 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-22 15:20:42,378 : INFO : EPOCH - 300 : training on 1242 raw words (645 effective words) took 0.0s, 166671 effective words/s\n",
      "2018-03-22 15:20:42,379 : INFO : training on a 372600 raw words (198749 effective words) took 2.9s, 67931 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "model2 = gensim.models.Word2Vec(sentence, min_count=1, size=300, workers=1, iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/championlin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \"\"\"\n",
      "/Users/championlin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "sentend=np.ones((300,),dtype=np.float32) \n",
    "\n",
    "vec_x=[]\n",
    "for sent in x_tok:\n",
    "    sentvec = [model2[w] for w in sent if w in model2]\n",
    "    vec_x.append(sentvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/championlin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/championlin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "vec_y=[]\n",
    "for sent in y_tok:\n",
    "    sentvec = [model2[w] for w in sent if w in model2]\n",
    "    vec_y.append(sentvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tok_sent in vec_x:\n",
    "    tok_sent[14:]=[]\n",
    "    tok_sent.append(sentend)\n",
    "    \n",
    "\n",
    "for tok_sent in vec_x:\n",
    "    if len(tok_sent)<15:\n",
    "        for i in range(15-len(tok_sent)):\n",
    "            tok_sent.append(sentend)    \n",
    "            \n",
    "for tok_sent in vec_y:\n",
    "    tok_sent[14:]=[]\n",
    "    tok_sent.append(sentend)\n",
    "    \n",
    "\n",
    "for tok_sent in vec_y:\n",
    "    if len(tok_sent)<15:\n",
    "        for i in range(15-len(tok_sent)):\n",
    "            tok_sent.append(sentend)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_x = np.array(vec_x)\n",
    "vec_y = np.array(vec_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1099601 , -0.27570388,  0.0572405 , ..., -0.02720477,\n",
       "        -0.09014867,  0.13563383],\n",
       "       [-0.08918212, -0.08937541,  0.01402676, ..., -0.04557258,\n",
       "        -0.02430875, -0.01232843],\n",
       "       [-0.19331002,  0.04042437,  0.17868067, ..., -0.34014365,\n",
       "        -0.23162116, -0.00680808],\n",
       "       ...,\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(vec_x, vec_y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 15, 300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"tanh\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"tanh\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=False, activation=\"tanh\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "# model.add(GRU(input_shape=(15, 300), units=300, return_sequences=True))\n",
    "# model.add(GRU(input_shape=(15, 300), units=300, return_sequences=True))\n",
    "# model.add(SimpleRNN(units=50, input_shape=(15, 50), activation=\"sigmoid\", return_sequences=True))\n",
    "# model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "# model.add(RepeatVector(15))\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"tanh\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"tanh\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"tanh\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.compile(loss='cosine_proximity', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/championlin/anaconda3/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "68/68 [==============================] - 6s 89ms/step - loss: -0.2250 - acc: 9.8039e-04 - val_loss: -0.5717 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.6165 - acc: 0.0020 - val_loss: -0.6316 - val_acc: 0.0481\n",
      "Epoch 3/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.6618 - acc: 0.0157 - val_loss: -0.6590 - val_acc: 0.0111\n",
      "Epoch 4/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.6870 - acc: 0.0069 - val_loss: -0.6817 - val_acc: 0.0074\n",
      "Epoch 5/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7033 - acc: 0.0206 - val_loss: -0.6938 - val_acc: 0.0185\n",
      "Epoch 6/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7139 - acc: 0.0216 - val_loss: -0.6972 - val_acc: 0.0148\n",
      "Epoch 7/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7199 - acc: 0.0225 - val_loss: -0.7034 - val_acc: 0.0259\n",
      "Epoch 8/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.7242 - acc: 0.0118 - val_loss: -0.7087 - val_acc: 0.0185\n",
      "Epoch 9/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.7247 - acc: 0.0118 - val_loss: -0.7119 - val_acc: 0.0185\n",
      "Epoch 10/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7288 - acc: 0.0167 - val_loss: -0.7133 - val_acc: 0.0148\n",
      "Epoch 11/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7252 - acc: 0.0235 - val_loss: -0.7142 - val_acc: 0.0481\n",
      "Epoch 12/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7378 - acc: 0.0422 - val_loss: -0.7146 - val_acc: 0.0852\n",
      "Epoch 13/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.7383 - acc: 0.0657 - val_loss: -0.7127 - val_acc: 0.0852\n",
      "Epoch 14/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.7403 - acc: 0.0696 - val_loss: -0.7189 - val_acc: 0.0852\n",
      "Epoch 15/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.7417 - acc: 0.0725 - val_loss: -0.7147 - val_acc: 0.0852\n",
      "Epoch 16/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7455 - acc: 0.0725 - val_loss: -0.7155 - val_acc: 0.0852\n",
      "Epoch 17/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7483 - acc: 0.0716 - val_loss: -0.7190 - val_acc: 0.0852\n",
      "Epoch 18/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7492 - acc: 0.0725 - val_loss: -0.7178 - val_acc: 0.0815\n",
      "Epoch 19/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.7486 - acc: 0.0676 - val_loss: -0.7156 - val_acc: 0.0815\n",
      "Epoch 20/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.7514 - acc: 0.0637 - val_loss: -0.7116 - val_acc: 0.0778\n",
      "Epoch 21/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.7515 - acc: 0.0510 - val_loss: -0.7154 - val_acc: 0.0815\n",
      "Epoch 22/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7539 - acc: 0.0471 - val_loss: -0.7211 - val_acc: 0.0704\n",
      "Epoch 23/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.7530 - acc: 0.0510 - val_loss: -0.7193 - val_acc: 0.0778\n",
      "Epoch 24/500\n",
      "68/68 [==============================] - 2s 26ms/step - loss: -0.7518 - acc: 0.0598 - val_loss: -0.7115 - val_acc: 0.0815\n",
      "Epoch 25/500\n",
      "68/68 [==============================] - 2s 22ms/step - loss: -0.7492 - acc: 0.0686 - val_loss: -0.7113 - val_acc: 0.0815\n",
      "Epoch 26/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7561 - acc: 0.0775 - val_loss: -0.7152 - val_acc: 0.0889\n",
      "Epoch 27/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.7498 - acc: 0.0833 - val_loss: -0.7125 - val_acc: 0.0852\n",
      "Epoch 28/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.7557 - acc: 0.0784 - val_loss: -0.7118 - val_acc: 0.0852\n",
      "Epoch 29/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.7537 - acc: 0.0725 - val_loss: -0.7180 - val_acc: 0.0889\n",
      "Epoch 30/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.7563 - acc: 0.0765 - val_loss: -0.7216 - val_acc: 0.0926\n",
      "Epoch 31/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.7516 - acc: 0.0794 - val_loss: -0.7238 - val_acc: 0.0889\n",
      "Epoch 32/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.7575 - acc: 0.0863 - val_loss: -0.6989 - val_acc: 0.0852\n",
      "Epoch 33/500\n",
      "68/68 [==============================] - 2s 26ms/step - loss: -0.7497 - acc: 0.0755 - val_loss: -0.7043 - val_acc: 0.0815\n",
      "Epoch 34/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.7540 - acc: 0.0686 - val_loss: -0.7244 - val_acc: 0.0815\n",
      "Epoch 35/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7580 - acc: 0.0627 - val_loss: -0.7252 - val_acc: 0.0815\n",
      "Epoch 36/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.7578 - acc: 0.0627 - val_loss: -0.7226 - val_acc: 0.0815\n",
      "Epoch 37/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7614 - acc: 0.0637 - val_loss: -0.7185 - val_acc: 0.0815\n",
      "Epoch 38/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7626 - acc: 0.0627 - val_loss: -0.7209 - val_acc: 0.0852\n",
      "Epoch 39/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7640 - acc: 0.0618 - val_loss: -0.7215 - val_acc: 0.0815\n",
      "Epoch 40/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7659 - acc: 0.0578 - val_loss: -0.7191 - val_acc: 0.0778\n",
      "Epoch 41/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7667 - acc: 0.0539 - val_loss: -0.7171 - val_acc: 0.0741\n",
      "Epoch 42/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7670 - acc: 0.0549 - val_loss: -0.7166 - val_acc: 0.0704\n",
      "Epoch 43/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7691 - acc: 0.0490 - val_loss: -0.7236 - val_acc: 0.0667\n",
      "Epoch 44/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7696 - acc: 0.0451 - val_loss: -0.7245 - val_acc: 0.0741\n",
      "Epoch 45/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.7720 - acc: 0.0549 - val_loss: -0.7165 - val_acc: 0.0741\n",
      "Epoch 46/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7685 - acc: 0.0657 - val_loss: -0.7217 - val_acc: 0.0778\n",
      "Epoch 47/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.7739 - acc: 0.0637 - val_loss: -0.7229 - val_acc: 0.0778\n",
      "Epoch 48/500\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.7724 - acc: 0.0647 - val_loss: -0.7242 - val_acc: 0.0778\n",
      "Epoch 49/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.7737 - acc: 0.0647 - val_loss: -0.7278 - val_acc: 0.0704\n",
      "Epoch 50/500\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.7745 - acc: 0.0608 - val_loss: -0.7220 - val_acc: 0.0704\n",
      "Epoch 51/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.7689 - acc: 0.0608 - val_loss: -0.7234 - val_acc: 0.0741\n",
      "Epoch 52/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.7745 - acc: 0.0588 - val_loss: -0.7245 - val_acc: 0.0778\n",
      "Epoch 53/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.7770 - acc: 0.0539 - val_loss: -0.7177 - val_acc: 0.0852\n",
      "Epoch 54/500\n",
      "68/68 [==============================] - 2s 26ms/step - loss: -0.7775 - acc: 0.0598 - val_loss: -0.7162 - val_acc: 0.0852\n",
      "Epoch 55/500\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.7801 - acc: 0.0716 - val_loss: -0.7114 - val_acc: 0.0889\n",
      "Epoch 56/500\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.7798 - acc: 0.0725 - val_loss: -0.7104 - val_acc: 0.0852\n",
      "Epoch 57/500\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.7812 - acc: 0.0775 - val_loss: -0.7203 - val_acc: 0.0889\n",
      "Epoch 58/500\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.7840 - acc: 0.0804 - val_loss: -0.7216 - val_acc: 0.0852\n",
      "Epoch 59/500\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.7832 - acc: 0.0657 - val_loss: -0.7185 - val_acc: 0.0889\n",
      "Epoch 60/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.7762 - acc: 0.0578 - val_loss: -0.7209 - val_acc: 0.0667\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 2s 26ms/step - loss: -0.7850 - acc: 0.0588 - val_loss: -0.7214 - val_acc: 0.0630\n",
      "Epoch 62/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.7860 - acc: 0.0578 - val_loss: -0.7173 - val_acc: 0.0667\n",
      "Epoch 63/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.7854 - acc: 0.0569 - val_loss: -0.7209 - val_acc: 0.0852\n",
      "Epoch 64/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.7873 - acc: 0.0647 - val_loss: -0.7219 - val_acc: 0.0815\n",
      "Epoch 65/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.7895 - acc: 0.0735 - val_loss: -0.7139 - val_acc: 0.0704\n",
      "Epoch 66/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.7847 - acc: 0.0686 - val_loss: -0.7068 - val_acc: 0.0741\n",
      "Epoch 67/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.7828 - acc: 0.0676 - val_loss: -0.7105 - val_acc: 0.0630\n",
      "Epoch 68/500\n",
      "68/68 [==============================] - 2s 29ms/step - loss: -0.7842 - acc: 0.0676 - val_loss: -0.7173 - val_acc: 0.0741\n",
      "Epoch 69/500\n",
      "68/68 [==============================] - 2s 30ms/step - loss: -0.7857 - acc: 0.0725 - val_loss: -0.7174 - val_acc: 0.0741\n",
      "Epoch 70/500\n",
      "68/68 [==============================] - 2s 31ms/step - loss: -0.7866 - acc: 0.0735 - val_loss: -0.7191 - val_acc: 0.0778\n",
      "Epoch 71/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.7906 - acc: 0.0735 - val_loss: -0.7216 - val_acc: 0.0815\n",
      "Epoch 72/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.7936 - acc: 0.1373 - val_loss: -0.7241 - val_acc: 0.0889\n",
      "Epoch 73/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.7931 - acc: 0.0706 - val_loss: -0.7245 - val_acc: 0.0852\n",
      "Epoch 74/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.7934 - acc: 0.0647 - val_loss: -0.7210 - val_acc: 0.0889\n",
      "Epoch 75/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.7943 - acc: 0.0716 - val_loss: -0.7147 - val_acc: 0.0889\n",
      "Epoch 76/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7983 - acc: 0.0716 - val_loss: -0.7100 - val_acc: 0.0778\n",
      "Epoch 77/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.7992 - acc: 0.0794 - val_loss: -0.7098 - val_acc: 0.0778\n",
      "Epoch 78/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8019 - acc: 0.0794 - val_loss: -0.7122 - val_acc: 0.0889\n",
      "Epoch 79/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.8045 - acc: 0.0794 - val_loss: -0.7066 - val_acc: 0.0889\n",
      "Epoch 80/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8037 - acc: 0.0784 - val_loss: -0.6965 - val_acc: 0.0852\n",
      "Epoch 81/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8039 - acc: 0.0794 - val_loss: -0.6956 - val_acc: 0.0778\n",
      "Epoch 82/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8049 - acc: 0.0765 - val_loss: -0.6918 - val_acc: 0.0778\n",
      "Epoch 83/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.8054 - acc: 0.0765 - val_loss: -0.6838 - val_acc: 0.0741\n",
      "Epoch 84/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8004 - acc: 0.0833 - val_loss: -0.6867 - val_acc: 0.0667\n",
      "Epoch 85/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.8005 - acc: 0.0775 - val_loss: -0.7204 - val_acc: 0.0667\n",
      "Epoch 86/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.8015 - acc: 0.0608 - val_loss: -0.7303 - val_acc: 0.0704\n",
      "Epoch 87/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.8020 - acc: 0.0608 - val_loss: -0.7284 - val_acc: 0.0778\n",
      "Epoch 88/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8051 - acc: 0.0725 - val_loss: -0.7227 - val_acc: 0.0778\n",
      "Epoch 89/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.8096 - acc: 0.0765 - val_loss: -0.7231 - val_acc: 0.0741\n",
      "Epoch 90/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8130 - acc: 0.0784 - val_loss: -0.7167 - val_acc: 0.0741\n",
      "Epoch 91/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8116 - acc: 0.0784 - val_loss: -0.7172 - val_acc: 0.0667\n",
      "Epoch 92/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8161 - acc: 0.0755 - val_loss: -0.7201 - val_acc: 0.0630\n",
      "Epoch 93/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8166 - acc: 0.0725 - val_loss: -0.7176 - val_acc: 0.0593\n",
      "Epoch 94/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8154 - acc: 0.0686 - val_loss: -0.7134 - val_acc: 0.0667\n",
      "Epoch 95/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8148 - acc: 0.0647 - val_loss: -0.7155 - val_acc: 0.0815\n",
      "Epoch 96/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.8156 - acc: 0.0755 - val_loss: -0.7022 - val_acc: 0.0815\n",
      "Epoch 97/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8163 - acc: 0.0725 - val_loss: -0.6830 - val_acc: 0.0778\n",
      "Epoch 98/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8045 - acc: 0.0725 - val_loss: -0.6957 - val_acc: 0.0815\n",
      "Epoch 99/500\n",
      "68/68 [==============================] - 2s 22ms/step - loss: -0.8146 - acc: 0.0755 - val_loss: -0.6931 - val_acc: 0.0778\n",
      "Epoch 100/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8140 - acc: 0.0745 - val_loss: -0.6848 - val_acc: 0.0630\n",
      "Epoch 101/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8200 - acc: 0.0716 - val_loss: -0.6840 - val_acc: 0.0667\n",
      "Epoch 102/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.8233 - acc: 0.0755 - val_loss: -0.7161 - val_acc: 0.0667\n",
      "Epoch 103/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8223 - acc: 0.0882 - val_loss: -0.7095 - val_acc: 0.0481\n",
      "Epoch 104/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8229 - acc: 0.0863 - val_loss: -0.7173 - val_acc: 0.0185\n",
      "Epoch 105/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8223 - acc: 0.0676 - val_loss: -0.7193 - val_acc: 0.0185\n",
      "Epoch 106/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.8278 - acc: 0.0598 - val_loss: -0.7137 - val_acc: 0.0185\n",
      "Epoch 107/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8272 - acc: 0.0647 - val_loss: -0.7177 - val_acc: 0.0667\n",
      "Epoch 108/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8306 - acc: 0.0765 - val_loss: -0.7181 - val_acc: 0.0630\n",
      "Epoch 109/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8313 - acc: 0.0814 - val_loss: -0.7172 - val_acc: 0.0667\n",
      "Epoch 110/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8296 - acc: 0.0882 - val_loss: -0.7175 - val_acc: 0.0630\n",
      "Epoch 111/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8309 - acc: 0.0843 - val_loss: -0.7259 - val_acc: 0.0593\n",
      "Epoch 112/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8361 - acc: 0.0824 - val_loss: -0.7228 - val_acc: 0.0593\n",
      "Epoch 113/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8315 - acc: 0.0873 - val_loss: -0.7265 - val_acc: 0.0296\n",
      "Epoch 114/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8338 - acc: 0.0784 - val_loss: -0.7241 - val_acc: 0.0333\n",
      "Epoch 115/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8368 - acc: 0.0833 - val_loss: -0.7243 - val_acc: 0.0222\n",
      "Epoch 116/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8421 - acc: 0.0696 - val_loss: -0.7129 - val_acc: 0.0630\n",
      "Epoch 117/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8407 - acc: 0.0804 - val_loss: -0.7096 - val_acc: 0.0667\n",
      "Epoch 118/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8390 - acc: 0.0804 - val_loss: -0.7108 - val_acc: 0.0667\n",
      "Epoch 119/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8363 - acc: 0.0814 - val_loss: -0.6899 - val_acc: 0.0630\n",
      "Epoch 120/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8306 - acc: 0.0794 - val_loss: -0.7041 - val_acc: 0.0667\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 19ms/step - loss: -0.8403 - acc: 0.0843 - val_loss: -0.7094 - val_acc: 0.0741\n",
      "Epoch 122/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8425 - acc: 0.0882 - val_loss: -0.7045 - val_acc: 0.0815\n",
      "Epoch 123/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8359 - acc: 0.0931 - val_loss: -0.7137 - val_acc: 0.0704\n",
      "Epoch 124/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8372 - acc: 0.0971 - val_loss: -0.7112 - val_acc: 0.0741\n",
      "Epoch 125/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8378 - acc: 0.0941 - val_loss: -0.7151 - val_acc: 0.0630\n",
      "Epoch 126/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8384 - acc: 0.0980 - val_loss: -0.7073 - val_acc: 0.0593\n",
      "Epoch 127/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8412 - acc: 0.0951 - val_loss: -0.7119 - val_acc: 0.0667\n",
      "Epoch 128/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8463 - acc: 0.0882 - val_loss: -0.7084 - val_acc: 0.0667\n",
      "Epoch 129/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8402 - acc: 0.0853 - val_loss: -0.7030 - val_acc: 0.0667\n",
      "Epoch 130/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8435 - acc: 0.0931 - val_loss: -0.6600 - val_acc: 0.0667\n",
      "Epoch 131/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8415 - acc: 0.1000 - val_loss: -0.6562 - val_acc: 0.0704\n",
      "Epoch 132/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.8471 - acc: 0.1039 - val_loss: -0.6673 - val_acc: 0.0667\n",
      "Epoch 133/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.8489 - acc: 0.1078 - val_loss: -0.6635 - val_acc: 0.0667\n",
      "Epoch 134/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8523 - acc: 0.0971 - val_loss: -0.6887 - val_acc: 0.0630\n",
      "Epoch 135/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8494 - acc: 0.0971 - val_loss: -0.6962 - val_acc: 0.0667\n",
      "Epoch 136/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8496 - acc: 0.0990 - val_loss: -0.7026 - val_acc: 0.0667\n",
      "Epoch 137/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8524 - acc: 0.0990 - val_loss: -0.7119 - val_acc: 0.0741\n",
      "Epoch 138/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8544 - acc: 0.0941 - val_loss: -0.7127 - val_acc: 0.0630\n",
      "Epoch 139/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8547 - acc: 0.1020 - val_loss: -0.7107 - val_acc: 0.0630\n",
      "Epoch 140/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8540 - acc: 0.0961 - val_loss: -0.7106 - val_acc: 0.0667\n",
      "Epoch 141/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8563 - acc: 0.0980 - val_loss: -0.7218 - val_acc: 0.0704\n",
      "Epoch 142/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.8632 - acc: 0.1049 - val_loss: -0.7197 - val_acc: 0.0630\n",
      "Epoch 143/500\n",
      "68/68 [==============================] - 2s 26ms/step - loss: -0.8627 - acc: 0.1078 - val_loss: -0.7115 - val_acc: 0.0667\n",
      "Epoch 144/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.8622 - acc: 0.1118 - val_loss: -0.7086 - val_acc: 0.0704\n",
      "Epoch 145/500\n",
      "68/68 [==============================] - 2s 22ms/step - loss: -0.8649 - acc: 0.1127 - val_loss: -0.7089 - val_acc: 0.0593\n",
      "Epoch 146/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8651 - acc: 0.1029 - val_loss: -0.7139 - val_acc: 0.0593\n",
      "Epoch 147/500\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.8679 - acc: 0.1088 - val_loss: -0.7151 - val_acc: 0.0667\n",
      "Epoch 148/500\n",
      "68/68 [==============================] - 2s 22ms/step - loss: -0.8662 - acc: 0.1059 - val_loss: -0.7077 - val_acc: 0.0630\n",
      "Epoch 149/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8623 - acc: 0.1245 - val_loss: -0.7090 - val_acc: 0.0667\n",
      "Epoch 150/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8674 - acc: 0.1147 - val_loss: -0.7070 - val_acc: 0.0667\n",
      "Epoch 151/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.8589 - acc: 0.1108 - val_loss: -0.7108 - val_acc: 0.0667\n",
      "Epoch 152/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8661 - acc: 0.1029 - val_loss: -0.6997 - val_acc: 0.0556\n",
      "Epoch 153/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8607 - acc: 0.1020 - val_loss: -0.7015 - val_acc: 0.0556\n",
      "Epoch 154/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.8622 - acc: 0.1049 - val_loss: -0.7005 - val_acc: 0.0519\n",
      "Epoch 155/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8692 - acc: 0.1098 - val_loss: -0.7004 - val_acc: 0.0519\n",
      "Epoch 156/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8684 - acc: 0.1167 - val_loss: -0.6964 - val_acc: 0.0630\n",
      "Epoch 157/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8682 - acc: 0.1186 - val_loss: -0.6889 - val_acc: 0.0741\n",
      "Epoch 158/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.8680 - acc: 0.1167 - val_loss: -0.6980 - val_acc: 0.0741\n",
      "Epoch 159/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.8681 - acc: 0.1176 - val_loss: -0.7061 - val_acc: 0.0704\n",
      "Epoch 160/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.8649 - acc: 0.1186 - val_loss: -0.7108 - val_acc: 0.0667\n",
      "Epoch 161/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.8690 - acc: 0.1186 - val_loss: -0.7076 - val_acc: 0.0444\n",
      "Epoch 162/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8704 - acc: 0.1157 - val_loss: -0.7088 - val_acc: 0.0407\n",
      "Epoch 163/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8659 - acc: 0.1206 - val_loss: -0.7062 - val_acc: 0.0519\n",
      "Epoch 164/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8739 - acc: 0.1196 - val_loss: -0.6997 - val_acc: 0.0593\n",
      "Epoch 165/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8695 - acc: 0.1127 - val_loss: -0.7031 - val_acc: 0.0704\n",
      "Epoch 166/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8658 - acc: 0.1127 - val_loss: -0.7115 - val_acc: 0.0704\n",
      "Epoch 167/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8696 - acc: 0.1147 - val_loss: -0.7114 - val_acc: 0.0704\n",
      "Epoch 168/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8725 - acc: 0.1235 - val_loss: -0.7033 - val_acc: 0.0630\n",
      "Epoch 169/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8754 - acc: 0.1275 - val_loss: -0.7007 - val_acc: 0.0704\n",
      "Epoch 170/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8784 - acc: 0.1265 - val_loss: -0.7030 - val_acc: 0.0741\n",
      "Epoch 171/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8806 - acc: 0.1275 - val_loss: -0.7044 - val_acc: 0.0630\n",
      "Epoch 172/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8822 - acc: 0.1255 - val_loss: -0.7027 - val_acc: 0.0667\n",
      "Epoch 173/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8809 - acc: 0.1206 - val_loss: -0.7058 - val_acc: 0.0667\n",
      "Epoch 174/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8813 - acc: 0.1216 - val_loss: -0.7086 - val_acc: 0.0667\n",
      "Epoch 175/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8763 - acc: 0.1235 - val_loss: -0.7089 - val_acc: 0.0704\n",
      "Epoch 176/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8769 - acc: 0.1245 - val_loss: -0.7011 - val_acc: 0.0630\n",
      "Epoch 177/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8754 - acc: 0.1196 - val_loss: -0.7010 - val_acc: 0.0704\n",
      "Epoch 178/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8774 - acc: 0.1275 - val_loss: -0.7020 - val_acc: 0.0704\n",
      "Epoch 179/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8784 - acc: 0.1265 - val_loss: -0.7058 - val_acc: 0.0741\n",
      "Epoch 180/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8774 - acc: 0.1265 - val_loss: -0.7061 - val_acc: 0.0741\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8770 - acc: 0.1294 - val_loss: -0.6990 - val_acc: 0.0704\n",
      "Epoch 182/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8753 - acc: 0.1275 - val_loss: -0.6878 - val_acc: 0.0593\n",
      "Epoch 183/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8732 - acc: 0.1294 - val_loss: -0.6935 - val_acc: 0.0593\n",
      "Epoch 184/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8758 - acc: 0.1294 - val_loss: -0.6837 - val_acc: 0.1111\n",
      "Epoch 185/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.8757 - acc: 0.1618 - val_loss: -0.6866 - val_acc: 0.0593\n",
      "Epoch 186/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.8809 - acc: 0.1382 - val_loss: -0.6681 - val_acc: 0.0815\n",
      "Epoch 187/500\n",
      "68/68 [==============================] - 2s 22ms/step - loss: -0.8809 - acc: 0.1422 - val_loss: -0.6746 - val_acc: 0.0704\n",
      "Epoch 188/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8754 - acc: 0.1275 - val_loss: -0.6797 - val_acc: 0.0519\n",
      "Epoch 189/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8735 - acc: 0.1284 - val_loss: -0.6731 - val_acc: 0.0593\n",
      "Epoch 190/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8797 - acc: 0.1324 - val_loss: -0.6417 - val_acc: 0.0630\n",
      "Epoch 191/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.8820 - acc: 0.1343 - val_loss: -0.6547 - val_acc: 0.0704\n",
      "Epoch 192/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.8838 - acc: 0.1412 - val_loss: -0.6973 - val_acc: 0.0741\n",
      "Epoch 193/500\n",
      "68/68 [==============================] - 2s 22ms/step - loss: -0.8844 - acc: 0.1392 - val_loss: -0.7059 - val_acc: 0.0741\n",
      "Epoch 194/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8878 - acc: 0.1441 - val_loss: -0.7006 - val_acc: 0.0852\n",
      "Epoch 195/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8875 - acc: 0.1520 - val_loss: -0.6927 - val_acc: 0.0926\n",
      "Epoch 196/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.8861 - acc: 0.1461 - val_loss: -0.6815 - val_acc: 0.0815\n",
      "Epoch 197/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.8903 - acc: 0.1510 - val_loss: -0.6739 - val_acc: 0.0852\n",
      "Epoch 198/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.8905 - acc: 0.1529 - val_loss: -0.6707 - val_acc: 0.0630\n",
      "Epoch 199/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8916 - acc: 0.1363 - val_loss: -0.6684 - val_acc: 0.1037\n",
      "Epoch 200/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8935 - acc: 0.1667 - val_loss: -0.6727 - val_acc: 0.0481\n",
      "Epoch 201/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8944 - acc: 0.1461 - val_loss: -0.6793 - val_acc: 0.0667\n",
      "Epoch 202/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8953 - acc: 0.1412 - val_loss: -0.6839 - val_acc: 0.0815\n",
      "Epoch 203/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8925 - acc: 0.1480 - val_loss: -0.6877 - val_acc: 0.0852\n",
      "Epoch 204/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.8887 - acc: 0.1353 - val_loss: -0.6865 - val_acc: 0.0778\n",
      "Epoch 205/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.8876 - acc: 0.1275 - val_loss: -0.6834 - val_acc: 0.0704\n",
      "Epoch 206/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.8904 - acc: 0.1441 - val_loss: -0.6811 - val_acc: 0.0704\n",
      "Epoch 207/500\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.8928 - acc: 0.1441 - val_loss: -0.6768 - val_acc: 0.0667\n",
      "Epoch 208/500\n",
      "68/68 [==============================] - 2s 26ms/step - loss: -0.8919 - acc: 0.1441 - val_loss: -0.6779 - val_acc: 0.0704\n",
      "Epoch 209/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.8928 - acc: 0.1500 - val_loss: -0.6720 - val_acc: 0.0778\n",
      "Epoch 210/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8926 - acc: 0.1461 - val_loss: -0.6695 - val_acc: 0.0778\n",
      "Epoch 211/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8950 - acc: 0.1549 - val_loss: -0.6661 - val_acc: 0.0778\n",
      "Epoch 212/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8975 - acc: 0.1539 - val_loss: -0.6751 - val_acc: 0.0667\n",
      "Epoch 213/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8982 - acc: 0.1549 - val_loss: -0.6786 - val_acc: 0.0704\n",
      "Epoch 214/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8993 - acc: 0.1569 - val_loss: -0.6761 - val_acc: 0.0704\n",
      "Epoch 215/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8981 - acc: 0.1539 - val_loss: -0.6733 - val_acc: 0.0741\n",
      "Epoch 216/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8987 - acc: 0.1588 - val_loss: -0.6765 - val_acc: 0.0778\n",
      "Epoch 217/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8970 - acc: 0.1529 - val_loss: -0.6800 - val_acc: 0.0741\n",
      "Epoch 218/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8995 - acc: 0.1500 - val_loss: -0.6835 - val_acc: 0.0741\n",
      "Epoch 219/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9013 - acc: 0.1333 - val_loss: -0.6843 - val_acc: 0.0778\n",
      "Epoch 220/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8991 - acc: 0.1382 - val_loss: -0.6871 - val_acc: 0.0778\n",
      "Epoch 221/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9018 - acc: 0.1500 - val_loss: -0.6849 - val_acc: 0.0778\n",
      "Epoch 222/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9026 - acc: 0.1578 - val_loss: -0.6821 - val_acc: 0.0741\n",
      "Epoch 223/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9025 - acc: 0.1657 - val_loss: -0.6823 - val_acc: 0.0815\n",
      "Epoch 224/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9051 - acc: 0.1716 - val_loss: -0.6846 - val_acc: 0.0778\n",
      "Epoch 225/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9054 - acc: 0.1676 - val_loss: -0.6869 - val_acc: 0.0741\n",
      "Epoch 226/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9036 - acc: 0.1657 - val_loss: -0.6860 - val_acc: 0.0741\n",
      "Epoch 227/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9052 - acc: 0.1608 - val_loss: -0.6813 - val_acc: 0.0704\n",
      "Epoch 228/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9065 - acc: 0.1598 - val_loss: -0.6749 - val_acc: 0.0704\n",
      "Epoch 229/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9041 - acc: 0.1725 - val_loss: -0.6724 - val_acc: 0.0704\n",
      "Epoch 230/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9048 - acc: 0.1667 - val_loss: -0.6744 - val_acc: 0.0704\n",
      "Epoch 231/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9056 - acc: 0.1657 - val_loss: -0.6759 - val_acc: 0.0704\n",
      "Epoch 232/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9063 - acc: 0.1559 - val_loss: -0.6765 - val_acc: 0.0704\n",
      "Epoch 233/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9059 - acc: 0.1520 - val_loss: -0.6737 - val_acc: 0.0704\n",
      "Epoch 234/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9054 - acc: 0.1539 - val_loss: -0.6688 - val_acc: 0.0815\n",
      "Epoch 235/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9043 - acc: 0.1500 - val_loss: -0.6541 - val_acc: 0.0889\n",
      "Epoch 236/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9057 - acc: 0.1578 - val_loss: -0.6424 - val_acc: 0.0815\n",
      "Epoch 237/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9045 - acc: 0.1716 - val_loss: -0.6593 - val_acc: 0.0815\n",
      "Epoch 238/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9057 - acc: 0.1784 - val_loss: -0.6639 - val_acc: 0.0852\n",
      "Epoch 239/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9037 - acc: 0.1784 - val_loss: -0.6533 - val_acc: 0.0852\n",
      "Epoch 240/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9031 - acc: 0.1775 - val_loss: -0.6609 - val_acc: 0.0741\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9037 - acc: 0.1765 - val_loss: -0.6774 - val_acc: 0.0704\n",
      "Epoch 242/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9051 - acc: 0.1618 - val_loss: -0.6852 - val_acc: 0.0667\n",
      "Epoch 243/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9076 - acc: 0.1500 - val_loss: -0.6895 - val_acc: 0.0704\n",
      "Epoch 244/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9090 - acc: 0.1520 - val_loss: -0.6870 - val_acc: 0.0704\n",
      "Epoch 245/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9089 - acc: 0.1588 - val_loss: -0.6825 - val_acc: 0.0704\n",
      "Epoch 246/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9089 - acc: 0.1569 - val_loss: -0.6769 - val_acc: 0.0741\n",
      "Epoch 247/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9103 - acc: 0.1686 - val_loss: -0.6757 - val_acc: 0.0704\n",
      "Epoch 248/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9107 - acc: 0.1608 - val_loss: -0.6770 - val_acc: 0.0704\n",
      "Epoch 249/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9106 - acc: 0.1667 - val_loss: -0.6730 - val_acc: 0.0630\n",
      "Epoch 250/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9112 - acc: 0.1706 - val_loss: -0.6656 - val_acc: 0.0704\n",
      "Epoch 251/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9109 - acc: 0.1745 - val_loss: -0.6634 - val_acc: 0.0704\n",
      "Epoch 252/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.9073 - acc: 0.1745 - val_loss: -0.6675 - val_acc: 0.0741\n",
      "Epoch 253/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9033 - acc: 0.1794 - val_loss: -0.6648 - val_acc: 0.0778\n",
      "Epoch 254/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.9036 - acc: 0.1755 - val_loss: -0.6671 - val_acc: 0.0741\n",
      "Epoch 255/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9034 - acc: 0.1804 - val_loss: -0.6797 - val_acc: 0.0852\n",
      "Epoch 256/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.8970 - acc: 0.1667 - val_loss: -0.6800 - val_acc: 0.0741\n",
      "Epoch 257/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.8990 - acc: 0.1686 - val_loss: -0.6749 - val_acc: 0.0667\n",
      "Epoch 258/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8997 - acc: 0.1706 - val_loss: -0.6688 - val_acc: 0.0556\n",
      "Epoch 259/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9014 - acc: 0.2039 - val_loss: -0.6649 - val_acc: 0.0852\n",
      "Epoch 260/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.8989 - acc: 0.1775 - val_loss: -0.6656 - val_acc: 0.0593\n",
      "Epoch 261/500\n",
      "68/68 [==============================] - 2s 22ms/step - loss: -0.9036 - acc: 0.1667 - val_loss: -0.6693 - val_acc: 0.0407\n",
      "Epoch 262/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.9005 - acc: 0.1520 - val_loss: -0.6731 - val_acc: 0.0481\n",
      "Epoch 263/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.9041 - acc: 0.1608 - val_loss: -0.6731 - val_acc: 0.0630\n",
      "Epoch 264/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.9003 - acc: 0.1657 - val_loss: -0.6696 - val_acc: 0.0704\n",
      "Epoch 265/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9065 - acc: 0.1725 - val_loss: -0.6657 - val_acc: 0.0630\n",
      "Epoch 266/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9061 - acc: 0.1667 - val_loss: -0.6645 - val_acc: 0.0741\n",
      "Epoch 267/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.9101 - acc: 0.1775 - val_loss: -0.6693 - val_acc: 0.0778\n",
      "Epoch 268/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9070 - acc: 0.1755 - val_loss: -0.6797 - val_acc: 0.0852\n",
      "Epoch 269/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9113 - acc: 0.1853 - val_loss: -0.6876 - val_acc: 0.0815\n",
      "Epoch 270/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9081 - acc: 0.1637 - val_loss: -0.6827 - val_acc: 0.0778\n",
      "Epoch 271/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9116 - acc: 0.1716 - val_loss: -0.6759 - val_acc: 0.0704\n",
      "Epoch 272/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9116 - acc: 0.1892 - val_loss: -0.6739 - val_acc: 0.0593\n",
      "Epoch 273/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9133 - acc: 0.1775 - val_loss: -0.6719 - val_acc: 0.0556\n",
      "Epoch 274/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9137 - acc: 0.1725 - val_loss: -0.6689 - val_acc: 0.0519\n",
      "Epoch 275/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9129 - acc: 0.1686 - val_loss: -0.6702 - val_acc: 0.0519\n",
      "Epoch 276/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9149 - acc: 0.1667 - val_loss: -0.6808 - val_acc: 0.0704\n",
      "Epoch 277/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9127 - acc: 0.1696 - val_loss: -0.6830 - val_acc: 0.0741\n",
      "Epoch 278/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.9129 - acc: 0.1725 - val_loss: -0.6802 - val_acc: 0.0741\n",
      "Epoch 279/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9138 - acc: 0.2676 - val_loss: -0.6776 - val_acc: 0.2407\n",
      "Epoch 280/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9091 - acc: 0.2735 - val_loss: -0.6761 - val_acc: 0.0741\n",
      "Epoch 281/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9100 - acc: 0.1804 - val_loss: -0.6698 - val_acc: 0.0741\n",
      "Epoch 282/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9123 - acc: 0.1725 - val_loss: -0.6677 - val_acc: 0.0741\n",
      "Epoch 283/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.9078 - acc: 0.1725 - val_loss: -0.6767 - val_acc: 0.0741\n",
      "Epoch 284/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9089 - acc: 0.1716 - val_loss: -0.6827 - val_acc: 0.0815\n",
      "Epoch 285/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9097 - acc: 0.1784 - val_loss: -0.6815 - val_acc: 0.0778\n",
      "Epoch 286/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9105 - acc: 0.1735 - val_loss: -0.6819 - val_acc: 0.0667\n",
      "Epoch 287/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9119 - acc: 0.1657 - val_loss: -0.6826 - val_acc: 0.0556\n",
      "Epoch 288/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9138 - acc: 0.1735 - val_loss: -0.6808 - val_acc: 0.0593\n",
      "Epoch 289/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9141 - acc: 0.1706 - val_loss: -0.6757 - val_acc: 0.0593\n",
      "Epoch 290/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9152 - acc: 0.1716 - val_loss: -0.6658 - val_acc: 0.0593\n",
      "Epoch 291/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9156 - acc: 0.1775 - val_loss: -0.6623 - val_acc: 0.0704\n",
      "Epoch 292/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9161 - acc: 0.1833 - val_loss: -0.6665 - val_acc: 0.0704\n",
      "Epoch 293/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9164 - acc: 0.1833 - val_loss: -0.6754 - val_acc: 0.0704\n",
      "Epoch 294/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9165 - acc: 0.1784 - val_loss: -0.6780 - val_acc: 0.0741\n",
      "Epoch 295/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.9165 - acc: 0.1794 - val_loss: -0.6768 - val_acc: 0.0778\n",
      "Epoch 296/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9181 - acc: 0.1765 - val_loss: -0.6733 - val_acc: 0.0704\n",
      "Epoch 297/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.9180 - acc: 0.1765 - val_loss: -0.6679 - val_acc: 0.0741\n",
      "Epoch 298/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9178 - acc: 0.1755 - val_loss: -0.6658 - val_acc: 0.0704\n",
      "Epoch 299/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9180 - acc: 0.1794 - val_loss: -0.6633 - val_acc: 0.0704\n",
      "Epoch 300/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9186 - acc: 0.1853 - val_loss: -0.6603 - val_acc: 0.0815\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9198 - acc: 0.1882 - val_loss: -0.6614 - val_acc: 0.0778\n",
      "Epoch 302/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9202 - acc: 0.1902 - val_loss: -0.6643 - val_acc: 0.0741\n",
      "Epoch 303/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9213 - acc: 0.1824 - val_loss: -0.6653 - val_acc: 0.0630\n",
      "Epoch 304/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9215 - acc: 0.1745 - val_loss: -0.6633 - val_acc: 0.0630\n",
      "Epoch 305/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9216 - acc: 0.1735 - val_loss: -0.6615 - val_acc: 0.0667\n",
      "Epoch 306/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9215 - acc: 0.1784 - val_loss: -0.6644 - val_acc: 0.0667\n",
      "Epoch 307/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9226 - acc: 0.1863 - val_loss: -0.6689 - val_acc: 0.0741\n",
      "Epoch 308/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9230 - acc: 0.1833 - val_loss: -0.6759 - val_acc: 0.0778\n",
      "Epoch 309/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9225 - acc: 0.1873 - val_loss: -0.6743 - val_acc: 0.0815\n",
      "Epoch 310/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9238 - acc: 0.1833 - val_loss: -0.6678 - val_acc: 0.0741\n",
      "Epoch 311/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9240 - acc: 0.1824 - val_loss: -0.6611 - val_acc: 0.0704\n",
      "Epoch 312/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9235 - acc: 0.1863 - val_loss: -0.6580 - val_acc: 0.0667\n",
      "Epoch 313/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9242 - acc: 0.1873 - val_loss: -0.6569 - val_acc: 0.0667\n",
      "Epoch 314/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9250 - acc: 0.1912 - val_loss: -0.6584 - val_acc: 0.0704\n",
      "Epoch 315/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9252 - acc: 0.1931 - val_loss: -0.6610 - val_acc: 0.0741\n",
      "Epoch 316/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9250 - acc: 0.2010 - val_loss: -0.6652 - val_acc: 0.0741\n",
      "Epoch 317/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9250 - acc: 0.2020 - val_loss: -0.6663 - val_acc: 0.0741\n",
      "Epoch 318/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9255 - acc: 0.2029 - val_loss: -0.6604 - val_acc: 0.0667\n",
      "Epoch 319/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9252 - acc: 0.1980 - val_loss: -0.6417 - val_acc: 0.0593\n",
      "Epoch 320/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9210 - acc: 0.1873 - val_loss: -0.6538 - val_acc: 0.0630\n",
      "Epoch 321/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9221 - acc: 0.1961 - val_loss: -0.6544 - val_acc: 0.0741\n",
      "Epoch 322/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9200 - acc: 0.1892 - val_loss: -0.6543 - val_acc: 0.1074\n",
      "Epoch 323/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9223 - acc: 0.2235 - val_loss: -0.6577 - val_acc: 0.0778\n",
      "Epoch 324/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9222 - acc: 0.1873 - val_loss: -0.6470 - val_acc: 0.0704\n",
      "Epoch 325/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9213 - acc: 0.1873 - val_loss: -0.6502 - val_acc: 0.0741\n",
      "Epoch 326/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9230 - acc: 0.1863 - val_loss: -0.6511 - val_acc: 0.0741\n",
      "Epoch 327/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9201 - acc: 0.1824 - val_loss: -0.6546 - val_acc: 0.0667\n",
      "Epoch 328/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9213 - acc: 0.1706 - val_loss: -0.6582 - val_acc: 0.0630\n",
      "Epoch 329/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.9202 - acc: 0.2020 - val_loss: -0.6497 - val_acc: 0.3296\n",
      "Epoch 330/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9225 - acc: 0.5794 - val_loss: -0.6348 - val_acc: 0.0556\n",
      "Epoch 331/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9243 - acc: 0.1912 - val_loss: -0.6254 - val_acc: 0.0556\n",
      "Epoch 332/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.9247 - acc: 0.1843 - val_loss: -0.6285 - val_acc: 0.0593\n",
      "Epoch 333/500\n",
      "68/68 [==============================] - 2s 27ms/step - loss: -0.9249 - acc: 0.1931 - val_loss: -0.6404 - val_acc: 0.0630\n",
      "Epoch 334/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9261 - acc: 0.1971 - val_loss: -0.6406 - val_acc: 0.1593\n",
      "Epoch 335/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9271 - acc: 0.3539 - val_loss: -0.6449 - val_acc: 0.0704\n",
      "Epoch 336/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9271 - acc: 0.2088 - val_loss: -0.6493 - val_acc: 0.0667\n",
      "Epoch 337/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9271 - acc: 0.1990 - val_loss: -0.6532 - val_acc: 0.0667\n",
      "Epoch 338/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9274 - acc: 0.2010 - val_loss: -0.6576 - val_acc: 0.0704\n",
      "Epoch 339/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9279 - acc: 0.1990 - val_loss: -0.6578 - val_acc: 0.0741\n",
      "Epoch 340/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9280 - acc: 0.2010 - val_loss: -0.6536 - val_acc: 0.0741\n",
      "Epoch 341/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9285 - acc: 0.1951 - val_loss: -0.6385 - val_acc: 0.0630\n",
      "Epoch 342/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9283 - acc: 0.1941 - val_loss: -0.6225 - val_acc: 0.0593\n",
      "Epoch 343/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9293 - acc: 0.1971 - val_loss: -0.6128 - val_acc: 0.0556\n",
      "Epoch 344/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9285 - acc: 0.1922 - val_loss: -0.6623 - val_acc: 0.0741\n",
      "Epoch 345/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9308 - acc: 0.2020 - val_loss: -0.6710 - val_acc: 0.0778\n",
      "Epoch 346/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9310 - acc: 0.1990 - val_loss: -0.6678 - val_acc: 0.0704\n",
      "Epoch 347/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9308 - acc: 0.1961 - val_loss: -0.6602 - val_acc: 0.0704\n",
      "Epoch 348/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9308 - acc: 0.1912 - val_loss: -0.6581 - val_acc: 0.0593\n",
      "Epoch 349/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9306 - acc: 0.1931 - val_loss: -0.6582 - val_acc: 0.0741\n",
      "Epoch 350/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9306 - acc: 0.2049 - val_loss: -0.6574 - val_acc: 0.0778\n",
      "Epoch 351/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9287 - acc: 0.2000 - val_loss: -0.6598 - val_acc: 0.0778\n",
      "Epoch 352/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9261 - acc: 0.1971 - val_loss: -0.6669 - val_acc: 0.0889\n",
      "Epoch 353/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9240 - acc: 0.1922 - val_loss: -0.6723 - val_acc: 0.0778\n",
      "Epoch 354/500\n",
      "68/68 [==============================] - 1s 15ms/step - loss: -0.9242 - acc: 0.1863 - val_loss: -0.6683 - val_acc: 0.0741\n",
      "Epoch 355/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9246 - acc: 0.1922 - val_loss: -0.6630 - val_acc: 0.0741\n",
      "Epoch 356/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9256 - acc: 0.1941 - val_loss: -0.6614 - val_acc: 0.0741\n",
      "Epoch 357/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9268 - acc: 0.2039 - val_loss: -0.6615 - val_acc: 0.0852\n",
      "Epoch 358/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9267 - acc: 0.2020 - val_loss: -0.6585 - val_acc: 0.0889\n",
      "Epoch 359/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9275 - acc: 0.2059 - val_loss: -0.6558 - val_acc: 0.0815\n",
      "Epoch 360/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9271 - acc: 0.2020 - val_loss: -0.6544 - val_acc: 0.0741\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9271 - acc: 0.2039 - val_loss: -0.6538 - val_acc: 0.0778\n",
      "Epoch 362/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9264 - acc: 0.2010 - val_loss: -0.6540 - val_acc: 0.0741\n",
      "Epoch 363/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9266 - acc: 0.1931 - val_loss: -0.6550 - val_acc: 0.0741\n",
      "Epoch 364/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9272 - acc: 0.1892 - val_loss: -0.6573 - val_acc: 0.0704\n",
      "Epoch 365/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9277 - acc: 0.1941 - val_loss: -0.6600 - val_acc: 0.0704\n",
      "Epoch 366/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9288 - acc: 0.1941 - val_loss: -0.6597 - val_acc: 0.0704\n",
      "Epoch 367/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.9290 - acc: 0.1980 - val_loss: -0.6604 - val_acc: 0.0815\n",
      "Epoch 368/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9293 - acc: 0.1971 - val_loss: -0.6625 - val_acc: 0.0778\n",
      "Epoch 369/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9296 - acc: 0.2020 - val_loss: -0.6638 - val_acc: 0.0852\n",
      "Epoch 370/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9302 - acc: 0.2010 - val_loss: -0.6638 - val_acc: 0.0815\n",
      "Epoch 371/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9310 - acc: 0.1971 - val_loss: -0.6605 - val_acc: 0.0704\n",
      "Epoch 372/500\n",
      "68/68 [==============================] - 2s 22ms/step - loss: -0.9315 - acc: 0.2000 - val_loss: -0.6589 - val_acc: 0.0667\n",
      "Epoch 373/500\n",
      "68/68 [==============================] - 1s 22ms/step - loss: -0.9318 - acc: 0.1961 - val_loss: -0.6596 - val_acc: 0.0667\n",
      "Epoch 374/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9323 - acc: 0.2029 - val_loss: -0.6549 - val_acc: 0.0667\n",
      "Epoch 375/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9308 - acc: 0.2029 - val_loss: -0.6519 - val_acc: 0.0667\n",
      "Epoch 376/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9302 - acc: 0.2039 - val_loss: -0.6555 - val_acc: 0.0704\n",
      "Epoch 377/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9303 - acc: 0.2118 - val_loss: -0.6597 - val_acc: 0.0704\n",
      "Epoch 378/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9322 - acc: 0.2471 - val_loss: -0.6655 - val_acc: 0.3296\n",
      "Epoch 379/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9327 - acc: 0.3676 - val_loss: -0.6689 - val_acc: 0.0778\n",
      "Epoch 380/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9311 - acc: 0.2000 - val_loss: -0.6688 - val_acc: 0.0815\n",
      "Epoch 381/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9320 - acc: 0.2059 - val_loss: -0.6645 - val_acc: 0.0852\n",
      "Epoch 382/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9330 - acc: 0.2098 - val_loss: -0.6586 - val_acc: 0.0889\n",
      "Epoch 383/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9334 - acc: 0.2000 - val_loss: -0.6549 - val_acc: 0.0852\n",
      "Epoch 384/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9337 - acc: 0.2118 - val_loss: -0.6559 - val_acc: 0.0778\n",
      "Epoch 385/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9341 - acc: 0.2186 - val_loss: -0.6586 - val_acc: 0.0704\n",
      "Epoch 386/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9343 - acc: 0.2137 - val_loss: -0.6593 - val_acc: 0.0704\n",
      "Epoch 387/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9346 - acc: 0.2167 - val_loss: -0.6579 - val_acc: 0.0704\n",
      "Epoch 388/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9350 - acc: 0.2167 - val_loss: -0.6561 - val_acc: 0.0778\n",
      "Epoch 389/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9351 - acc: 0.2176 - val_loss: -0.6553 - val_acc: 0.0741\n",
      "Epoch 390/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9347 - acc: 0.2176 - val_loss: -0.6568 - val_acc: 0.0704\n",
      "Epoch 391/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9348 - acc: 0.2216 - val_loss: -0.6579 - val_acc: 0.0741\n",
      "Epoch 392/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9352 - acc: 0.2157 - val_loss: -0.6563 - val_acc: 0.0889\n",
      "Epoch 393/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9350 - acc: 0.2118 - val_loss: -0.6540 - val_acc: 0.0889\n",
      "Epoch 394/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9348 - acc: 0.2157 - val_loss: -0.6524 - val_acc: 0.0815\n",
      "Epoch 395/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9351 - acc: 0.2118 - val_loss: -0.6532 - val_acc: 0.0741\n",
      "Epoch 396/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9350 - acc: 0.2088 - val_loss: -0.6538 - val_acc: 0.0704\n",
      "Epoch 397/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9356 - acc: 0.2206 - val_loss: -0.6529 - val_acc: 0.0741\n",
      "Epoch 398/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9355 - acc: 0.2137 - val_loss: -0.6527 - val_acc: 0.0741\n",
      "Epoch 399/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9354 - acc: 0.2127 - val_loss: -0.6566 - val_acc: 0.0778\n",
      "Epoch 400/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9363 - acc: 0.2059 - val_loss: -0.6634 - val_acc: 0.0852\n",
      "Epoch 401/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9353 - acc: 0.2137 - val_loss: -0.6653 - val_acc: 0.0815\n",
      "Epoch 402/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9354 - acc: 0.2255 - val_loss: -0.6635 - val_acc: 0.0815\n",
      "Epoch 403/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9355 - acc: 0.2137 - val_loss: -0.6621 - val_acc: 0.0852\n",
      "Epoch 404/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9344 - acc: 0.2039 - val_loss: -0.6616 - val_acc: 0.0852\n",
      "Epoch 405/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9353 - acc: 0.2059 - val_loss: -0.6633 - val_acc: 0.0889\n",
      "Epoch 406/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9354 - acc: 0.2069 - val_loss: -0.6590 - val_acc: 0.0815\n",
      "Epoch 407/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9343 - acc: 0.2118 - val_loss: -0.6505 - val_acc: 0.0815\n",
      "Epoch 408/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9331 - acc: 0.2147 - val_loss: -0.6416 - val_acc: 0.0852\n",
      "Epoch 409/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9334 - acc: 0.2216 - val_loss: -0.6391 - val_acc: 0.0815\n",
      "Epoch 410/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9331 - acc: 0.2157 - val_loss: -0.6337 - val_acc: 0.0778\n",
      "Epoch 411/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9337 - acc: 0.2196 - val_loss: -0.6451 - val_acc: 0.0815\n",
      "Epoch 412/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9357 - acc: 0.2225 - val_loss: -0.6550 - val_acc: 0.0741\n",
      "Epoch 413/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9355 - acc: 0.2167 - val_loss: -0.6596 - val_acc: 0.0741\n",
      "Epoch 414/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9358 - acc: 0.2098 - val_loss: -0.6590 - val_acc: 0.0815\n",
      "Epoch 415/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9359 - acc: 0.2088 - val_loss: -0.6591 - val_acc: 0.0852\n",
      "Epoch 416/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9355 - acc: 0.2108 - val_loss: -0.6612 - val_acc: 0.0815\n",
      "Epoch 417/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9324 - acc: 0.2235 - val_loss: -0.6547 - val_acc: 0.0778\n",
      "Epoch 418/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9232 - acc: 0.2176 - val_loss: -0.6564 - val_acc: 0.3148\n",
      "Epoch 419/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9265 - acc: 0.4216 - val_loss: -0.6545 - val_acc: 0.0667\n",
      "Epoch 420/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9252 - acc: 0.2157 - val_loss: -0.6513 - val_acc: 0.0667\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9192 - acc: 0.1892 - val_loss: -0.6301 - val_acc: 0.0556\n",
      "Epoch 422/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9183 - acc: 0.1882 - val_loss: -0.5978 - val_acc: 0.0556\n",
      "Epoch 423/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9181 - acc: 0.2049 - val_loss: -0.6112 - val_acc: 0.0519\n",
      "Epoch 424/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9217 - acc: 0.1980 - val_loss: -0.6388 - val_acc: 0.0667\n",
      "Epoch 425/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9232 - acc: 0.2108 - val_loss: -0.6561 - val_acc: 0.0778\n",
      "Epoch 426/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9244 - acc: 0.2029 - val_loss: -0.6624 - val_acc: 0.0852\n",
      "Epoch 427/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9250 - acc: 0.2000 - val_loss: -0.6628 - val_acc: 0.0926\n",
      "Epoch 428/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9266 - acc: 0.1980 - val_loss: -0.6620 - val_acc: 0.0926\n",
      "Epoch 429/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9267 - acc: 0.2020 - val_loss: -0.6619 - val_acc: 0.0926\n",
      "Epoch 430/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9276 - acc: 0.2137 - val_loss: -0.6587 - val_acc: 0.0926\n",
      "Epoch 431/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9275 - acc: 0.2127 - val_loss: -0.6542 - val_acc: 0.0815\n",
      "Epoch 432/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9264 - acc: 0.2157 - val_loss: -0.6558 - val_acc: 0.0778\n",
      "Epoch 433/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9263 - acc: 0.2137 - val_loss: -0.6597 - val_acc: 0.0815\n",
      "Epoch 434/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9276 - acc: 0.2059 - val_loss: -0.6609 - val_acc: 0.0815\n",
      "Epoch 435/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9299 - acc: 0.2078 - val_loss: -0.6577 - val_acc: 0.0741\n",
      "Epoch 436/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9314 - acc: 0.2294 - val_loss: -0.6522 - val_acc: 0.0926\n",
      "Epoch 437/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9308 - acc: 0.2069 - val_loss: -0.6548 - val_acc: 0.0741\n",
      "Epoch 438/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9330 - acc: 0.2127 - val_loss: -0.6637 - val_acc: 0.0778\n",
      "Epoch 439/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9327 - acc: 0.2225 - val_loss: -0.6683 - val_acc: 0.0815\n",
      "Epoch 440/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9341 - acc: 0.2206 - val_loss: -0.6707 - val_acc: 0.0963\n",
      "Epoch 441/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9345 - acc: 0.2245 - val_loss: -0.6680 - val_acc: 0.0852\n",
      "Epoch 442/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9353 - acc: 0.2186 - val_loss: -0.6583 - val_acc: 0.0741\n",
      "Epoch 443/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9315 - acc: 0.2088 - val_loss: -0.6588 - val_acc: 0.0778\n",
      "Epoch 444/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9318 - acc: 0.2137 - val_loss: -0.6611 - val_acc: 0.0815\n",
      "Epoch 445/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9248 - acc: 0.2206 - val_loss: -0.6652 - val_acc: 0.0741\n",
      "Epoch 446/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9274 - acc: 0.2206 - val_loss: -0.6627 - val_acc: 0.0704\n",
      "Epoch 447/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9310 - acc: 0.2118 - val_loss: -0.6570 - val_acc: 0.0630\n",
      "Epoch 448/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9289 - acc: 0.2039 - val_loss: -0.6583 - val_acc: 0.0630\n",
      "Epoch 449/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9303 - acc: 0.2078 - val_loss: -0.6564 - val_acc: 0.0593\n",
      "Epoch 450/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9293 - acc: 0.2147 - val_loss: -0.6556 - val_acc: 0.0630\n",
      "Epoch 451/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9319 - acc: 0.2176 - val_loss: -0.6522 - val_acc: 0.0741\n",
      "Epoch 452/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9315 - acc: 0.2294 - val_loss: -0.6519 - val_acc: 0.0852\n",
      "Epoch 453/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9329 - acc: 0.2225 - val_loss: -0.6542 - val_acc: 0.0926\n",
      "Epoch 454/500\n",
      "68/68 [==============================] - 1s 17ms/step - loss: -0.9345 - acc: 0.2265 - val_loss: -0.6546 - val_acc: 0.0852\n",
      "Epoch 455/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9343 - acc: 0.2186 - val_loss: -0.6533 - val_acc: 0.0852\n",
      "Epoch 456/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9354 - acc: 0.2049 - val_loss: -0.6522 - val_acc: 0.0815\n",
      "Epoch 457/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9358 - acc: 0.2157 - val_loss: -0.6499 - val_acc: 0.0815\n",
      "Epoch 458/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9373 - acc: 0.2167 - val_loss: -0.6480 - val_acc: 0.0704\n",
      "Epoch 459/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9381 - acc: 0.2216 - val_loss: -0.6464 - val_acc: 0.0704\n",
      "Epoch 460/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9386 - acc: 0.2255 - val_loss: -0.6463 - val_acc: 0.0741\n",
      "Epoch 461/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9392 - acc: 0.2275 - val_loss: -0.6485 - val_acc: 0.0741\n",
      "Epoch 462/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9397 - acc: 0.2284 - val_loss: -0.6508 - val_acc: 0.0741\n",
      "Epoch 463/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9398 - acc: 0.2275 - val_loss: -0.6521 - val_acc: 0.0852\n",
      "Epoch 464/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9402 - acc: 0.2324 - val_loss: -0.6526 - val_acc: 0.0852\n",
      "Epoch 465/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9409 - acc: 0.2314 - val_loss: -0.6517 - val_acc: 0.0815\n",
      "Epoch 466/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9407 - acc: 0.2304 - val_loss: -0.6511 - val_acc: 0.0852\n",
      "Epoch 467/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9415 - acc: 0.2333 - val_loss: -0.6491 - val_acc: 0.0852\n",
      "Epoch 468/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9412 - acc: 0.2363 - val_loss: -0.6462 - val_acc: 0.0852\n",
      "Epoch 469/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9407 - acc: 0.2314 - val_loss: -0.6386 - val_acc: 0.0852\n",
      "Epoch 470/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9370 - acc: 0.2304 - val_loss: -0.6465 - val_acc: 0.0852\n",
      "Epoch 471/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9386 - acc: 0.2294 - val_loss: -0.6518 - val_acc: 0.0778\n",
      "Epoch 472/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9342 - acc: 0.2186 - val_loss: -0.6568 - val_acc: 0.0815\n",
      "Epoch 473/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9384 - acc: 0.2647 - val_loss: -0.6579 - val_acc: 0.0852\n",
      "Epoch 474/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9360 - acc: 0.2324 - val_loss: -0.6582 - val_acc: 0.0852\n",
      "Epoch 475/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9358 - acc: 0.2225 - val_loss: -0.6603 - val_acc: 0.0852\n",
      "Epoch 476/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9351 - acc: 0.2294 - val_loss: -0.6575 - val_acc: 0.0889\n",
      "Epoch 477/500\n",
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9363 - acc: 0.2324 - val_loss: -0.6526 - val_acc: 0.0852\n",
      "Epoch 478/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9373 - acc: 0.2333 - val_loss: -0.6507 - val_acc: 0.0778\n",
      "Epoch 479/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9368 - acc: 0.2225 - val_loss: -0.6496 - val_acc: 0.0741\n",
      "Epoch 480/500\n",
      "68/68 [==============================] - 1s 16ms/step - loss: -0.9382 - acc: 0.2186 - val_loss: -0.6490 - val_acc: 0.0704\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 18ms/step - loss: -0.9396 - acc: 0.2265 - val_loss: -0.6493 - val_acc: 0.0704\n",
      "Epoch 482/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9394 - acc: 0.2304 - val_loss: -0.6508 - val_acc: 0.0741\n",
      "Epoch 483/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.9389 - acc: 0.2343 - val_loss: -0.6540 - val_acc: 0.0778\n",
      "Epoch 484/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.9398 - acc: 0.2324 - val_loss: -0.6572 - val_acc: 0.0778\n",
      "Epoch 485/500\n",
      "68/68 [==============================] - 2s 26ms/step - loss: -0.9406 - acc: 0.2333 - val_loss: -0.6563 - val_acc: 0.0778\n",
      "Epoch 486/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9411 - acc: 0.2353 - val_loss: -0.6496 - val_acc: 0.0741\n",
      "Epoch 487/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9410 - acc: 0.2343 - val_loss: -0.6463 - val_acc: 0.0852\n",
      "Epoch 488/500\n",
      "68/68 [==============================] - 1s 19ms/step - loss: -0.9411 - acc: 0.2363 - val_loss: -0.6442 - val_acc: 0.0852\n",
      "Epoch 489/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9428 - acc: 0.2412 - val_loss: -0.6475 - val_acc: 0.0852\n",
      "Epoch 490/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.9427 - acc: 0.2314 - val_loss: -0.6516 - val_acc: 0.0889\n",
      "Epoch 491/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9428 - acc: 0.2353 - val_loss: -0.6546 - val_acc: 0.0852\n",
      "Epoch 492/500\n",
      "68/68 [==============================] - 2s 23ms/step - loss: -0.9422 - acc: 0.2392 - val_loss: -0.6564 - val_acc: 0.1000\n",
      "Epoch 493/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9419 - acc: 0.2627 - val_loss: -0.6523 - val_acc: 0.0889\n",
      "Epoch 494/500\n",
      "68/68 [==============================] - 1s 21ms/step - loss: -0.9434 - acc: 0.2471 - val_loss: -0.6482 - val_acc: 0.0852\n",
      "Epoch 495/500\n",
      "68/68 [==============================] - 1s 20ms/step - loss: -0.9436 - acc: 0.2471 - val_loss: -0.6479 - val_acc: 0.0778\n",
      "Epoch 496/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.9441 - acc: 0.2480 - val_loss: -0.6493 - val_acc: 0.0815\n",
      "Epoch 497/500\n",
      "68/68 [==============================] - 2s 24ms/step - loss: -0.9449 - acc: 0.2490 - val_loss: -0.6479 - val_acc: 0.0741\n",
      "Epoch 498/500\n",
      "68/68 [==============================] - 2s 26ms/step - loss: -0.9449 - acc: 0.2461 - val_loss: -0.6491 - val_acc: 0.0778\n",
      "Epoch 499/500\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.9422 - acc: 0.2451 - val_loss: -0.6490 - val_acc: 0.0815\n",
      "Epoch 500/500\n",
      "68/68 [==============================] - 2s 28ms/step - loss: -0.9413 - acc: 0.2480 - val_loss: -0.6499 - val_acc: 0.0815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a472b2b70>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, nb_epoch=500,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('LSTM500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 16:13:55,606 : INFO : saving Word2Vec object under con_model.bin, separately None\n",
      "2018-03-22 16:13:55,610 : INFO : not storing attribute vectors_norm\n",
      "2018-03-22 16:13:55,616 : INFO : not storing attribute cum_table\n",
      "2018-03-22 16:13:55,631 : INFO : saved con_model.bin\n"
     ]
    }
   ],
   "source": [
    "model2.save('con_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
